# ADR-006: Redis Caching Strategy for Account Statements

## Status

Implemented

## Context

The mattilda_challenge system provides account statement endpoints that aggregate financial data across multiple entities:

- **Student Account Statement**: Aggregates invoices, payments, and late fees for a single student
- **School Account Statement**: Aggregates data across all students in a school

These endpoints are computationally expensive because they require:

1. **Aggregate queries**: JOIN across schools, students, invoices, and payments tables
2. **Late fee iteration**: Per-invoice calculation for overdue invoices (cannot be expressed as simple SQL SUM)

As documented in [ADR-004](ADR-004-postgresql-persistence.md#8-repository-calculation), account statement generation involves two database operations, making these endpoints candidates for caching.

### Performance Characteristics

| Endpoint | Query Complexity | Expected Latency (uncached) |
|----------|------------------|----------------------------|
| Student account statement | 1 aggregate + N late fee calculations | 50-200ms |
| School account statement | 1 large aggregate + M×N late fee calculations | 200-1000ms |

Where:
- N = number of overdue invoices for a student (typically 0-5)
- M = number of students in school (could be 100+)

### Project Context

The Mattilda Challenge PDF lists caching as an **optional extra** that "adds points" but is not required:

> **EXTRAS (no obligatorios, pero suman puntos)**
> - Cache (Redis u otro) para algunos endpoints de lectura.

Given this context, the caching implementation should be:
- **Simple**: TTL-based invalidation, no complex event systems
- **Non-critical**: System works correctly without cache (fail-open)
- **Focused**: Cache only the most expensive operations

### Related ADRs

- **[ADR-001](ADR-001-project-initialization.md)**: Clean Architecture, ABC ports, infrastructure isolation
- **[ADR-002](ADR-002-domain-model.md)**: Account statement structure, late fee calculation
- **[ADR-004](ADR-004-postgresql-persistence.md)**: Account statement repository implementation
- **[ADR-005](ADR-005-rest-api-design.md)**: Account statement endpoints

---

## Decision

### 1. Cache Scope

**Cached:**
- Student account statements (`StudentAccountStatement`)
- School account statements (`SchoolAccountStatement`)

**Not Cached:**
- Individual entity lookups (invoices, students, schools, payments)
- Late fee calculations in isolation
- List/search endpoints

**Rationale**: Account statements are the most expensive operations and have the best cache hit potential (read-heavy, relatively stable data). Individual entity lookups are fast enough without caching, and the added complexity isn't justified for this project scope.

---

### 2. Technology Stack

| Component | Choice | Rationale |
|-----------|--------|-----------|
| Cache Store | Redis 7+ | Already in tech stack (ADR-001), simple key-value model |
| Client Library | redis-py (async) | Official Python client with async support |
| Serialization | JSON | Human-readable, no additional dependencies |

---

### 3. Cache Invalidation Strategy: TTL-Only

We use **time-based invalidation (TTL)** exclusively, without event-driven invalidation.

```python
# Cache entry lifecycle
SET key value EX 300  # Set with 5-minute TTL
GET key               # Returns value or None (expired)
```

**Configuration:**

| Setting | Value | Rationale |
|---------|-------|-----------|
| TTL | 300 seconds (5 minutes) | Balance between freshness and cache hit rate |
| Max staleness | 5 minutes | Acceptable for dashboard/reporting data |

**Why TTL-only (not event-driven invalidation):**

| Aspect | TTL-Only | Event-Driven |
|--------|----------|--------------|
| Implementation complexity | Low | High |
| Write path impact | None | Must track affected keys |
| Consistency guarantee | Eventual (≤5 min) | Immediate |
| Failure modes | Simple timeout | Complex (missed events, orphan keys) |
| Appropriate for | Dashboard data | Real-time financial transactions |

For account statements (reporting/dashboard use case), 5-minute staleness is acceptable. A student viewing their balance after making a payment will see updated data within 5 minutes at most.

**Trade-off acknowledged**: After a payment is recorded, cached account statements may show stale data for up to 5 minutes. This is acceptable for the project scope and avoids significant complexity in write paths.

**Time-sensitive data invariant**: Cached statements represent a snapshot at `statement_date`. Late fees are computed at cache-write time and may drift as time passes; this drift is bounded by TTL (maximum 5 minutes of late-fee staleness). Cache stampede is acceptable at this stage due to low write frequency and bounded TTL; mitigation (e.g., distributed locking) is documented in Future Enhancements but intentionally deferred.

---

### 4. Cache Key Design

**Format**: `mattilda:cache:v1:account_statement:{entity_type}:{uuid}`

**Examples:**
```
mattilda:cache:v1:account_statement:student:550e8400-e29b-41d4-a716-446655440000
mattilda:cache:v1:account_statement:school:450e8400-e29b-41d4-a716-446655440001
```

**Key components:**

| Component | Purpose |
|-----------|---------|
| `mattilda` | Application namespace (prevents collision with other apps) |
| `cache` | Distinguishes from other Redis uses (sessions, queues, etc.) |
| `v1` | Cache schema version (allows invalidating all keys on schema change) |
| `account_statement` | Data type |
| `student` / `school` | Entity type |
| `{uuid}` | Entity identifier |

**Benefits:**
- **Readable**: Easy to inspect with `redis-cli KEYS "mattilda:cache:*"`
- **Versionable**: Bump `v1` to `v2` to invalidate all cached data on schema change
- **Namespaced**: Safe to share Redis instance with other applications
- **Debuggable**: Can manually delete specific keys during development

---

### 5. Architecture: Ports and Adapters

Following the established pattern from [ADR-001](ADR-001-project-initialization.md) and [ADR-004](ADR-004-postgresql-persistence.md), we treat Redis cache as an external dependency with ports in the application layer and adapters in the infrastructure layer.

#### 5.1 Project Structure

```
src/mattilda_challenge/
├── application/
│   └── ports/
│       ├── __init__.py
│       ├── time_provider.py                    # Existing
│       ├── student_account_statement_cache.py  # NEW: Student cache port
│       └── school_account_statement_cache.py   # NEW: School cache port
├── infrastructure/
│   ├── redis/                                  # NEW: Redis-specific code
│   │   ├── __init__.py
│   │   └── client.py                           # Connection setup, config
│   └── adapters/
│       ├── __init__.py
│       ├── invoice_repository/                 # Existing
│       ├── student_account_statement_cache/    # NEW: Student cache adapters
│       │   ├── __init__.py
│       │   ├── redis.py                        # Redis implementation
│       │   └── null.py                         # Null implementation
│       └── school_account_statement_cache/     # NEW: School cache adapters
│           ├── __init__.py
│           ├── redis.py                        # Redis implementation
│           └── null.py                         # Null implementation
```

#### 5.2 Port Interfaces (Application Layer)

Domain-specific cache ports provide type safety and encapsulate serialization concerns:

```python
# application/ports/account_statement_cache.py
from __future__ import annotations

from abc import ABC, abstractmethod

from mattilda_challenge.domain.value_objects import StudentId, SchoolId
from mattilda_challenge.application.dtos import (
    StudentAccountStatement,
    SchoolAccountStatement,
)


class StudentAccountStatementCache(ABC):
    """
    Port for caching student account statements.
    
    Contract:
    - get() returns None on cache miss (not found or expired)
    - get() returns None on cache failure (fail-open)
    - set() is best-effort (failures are logged, not raised)
    - Implementations handle serialization internally
    """
    
    @abstractmethod
    async def get(self, student_id: StudentId) -> StudentAccountStatement | None:
        """
        Retrieve cached student account statement.
        
        Args:
            student_id: Student identifier
            
        Returns:
            Cached statement or None if not found/expired/error
        """
        ...
    
    @abstractmethod
    async def set(self, statement: StudentAccountStatement) -> None:
        """
        Cache student account statement with TTL.
        
        Args:
            statement: Account statement to cache
            
        Note:
            Failures are logged but not raised (fail-open).
            TTL is configured in the implementation.
        """
        ...


class SchoolAccountStatementCache(ABC):
    """
    Port for caching school account statements.
    
    Same contract as StudentAccountStatementCache.
    """
    
    @abstractmethod
    async def get(self, school_id: SchoolId) -> SchoolAccountStatement | None:
        """
        Retrieve cached school account statement.
        
        Args:
            school_id: School identifier
            
        Returns:
            Cached statement or None if not found/expired/error
        """
        ...
    
    @abstractmethod
    async def set(self, statement: SchoolAccountStatement) -> None:
        """
        Cache school account statement with TTL.
        
        Args:
            statement: Account statement to cache
            
        Note:
            Failures are logged but not raised (fail-open).
        """
        ...
```

**Design decisions:**

1. **Separate ports per entity type**: Rather than a generic `Cache[T]` port, we have `StudentAccountStatementCache` and `SchoolAccountStatementCache`. This provides:
   - Type safety at compile time
   - Clear contracts per data type
   - Flexibility to have different TTLs or serialization per type

2. **No `delete()` method**: Since we use TTL-only invalidation, explicit deletion is not needed. If event-driven invalidation is added later, the port can be extended.

3. **Fail-open contract**: Errors return `None` (cache miss) rather than raising exceptions. The use case always falls back to the database.

#### 5.3 Redis Client Setup (Infrastructure Layer)

```python
# infrastructure/redis/client.py
from __future__ import annotations

import logging
from typing import AsyncGenerator

from redis.asyncio import Redis, ConnectionPool

from mattilda_challenge.config import settings

logger = logging.getLogger(__name__)


# Connection pool (shared across all cache adapters)
_pool: ConnectionPool | None = None


async def get_redis_pool() -> ConnectionPool:
    """
    Get or create Redis connection pool.
    
    Lazily initializes the pool on first call.
    """
    global _pool
    if _pool is None:
        _pool = ConnectionPool.from_url(
            settings.redis_url,  # redis://localhost:6379/0
            max_connections=10,
            decode_responses=True,  # Return strings, not bytes
        )
    return _pool


async def get_redis_client() -> AsyncGenerator[Redis, None]:
    """
    Dependency injection for Redis client.
    
    Usage in FastAPI:
        @app.get("/...")
        async def endpoint(
            redis: Redis = Depends(get_redis_client)
        ):
            ...
    
    Yields:
        Redis client instance from pool
    """
    pool = await get_redis_pool()
    client = Redis(connection_pool=pool)
    try:
        yield client
    finally:
        await client.aclose()


async def close_redis_pool() -> None:
    """
    Close Redis connection pool on application shutdown.
    
    Call from FastAPI lifespan handler.
    """
    global _pool
    if _pool is not None:
        await _pool.disconnect()
        _pool = None
```

**Client lifecycle notes:**
- **Connection pool**: A single `ConnectionPool` is shared across all cache adapters; Redis clients are lightweight handles over this shared pool
- **Request-scoped clients**: `get_redis_client()` yields a client per request, but actual TCP connections are pooled and reused
- **Graceful shutdown**: `close_redis_pool()` should be called from FastAPI's lifespan handler to clean up connections

**Configuration (in `config.py`):**
```python
class Settings(BaseSettings):
    # ... existing settings
    
    redis_url: str = "redis://localhost:6379/0"
    cache_ttl_seconds: int = 300  # 5 minutes
    
    class Config:
        env_file = ".env"
```

#### 5.4 Cache Adapter Implementation (Infrastructure Layer)

```python
# infrastructure/adapters/student_account_statement_cache/redis.py
from __future__ import annotations

import json
import logging
from datetime import datetime
from decimal import Decimal, InvalidOperation

from redis.asyncio import Redis
from redis.exceptions import RedisError

from mattilda_challenge.application.dtos import StudentAccountStatement
from mattilda_challenge.application.ports import StudentAccountStatementCache
from mattilda_challenge.config import get_settings
from mattilda_challenge.domain.exceptions import InvalidStudentIdError
from mattilda_challenge.domain.value_objects import StudentId

logger = logging.getLogger(__name__)
_settings = get_settings()


class RedisStudentAccountStatementCache(StudentAccountStatementCache):
    """
    Redis implementation of StudentAccountStatementCache port.
    
    Uses JSON serialization with string decimals for precision.
    Implements fail-open pattern: errors return None, not exceptions.
    """
    
    KEY_PREFIX = "mattilda:cache:v1:account_statement:student"

    def __init__(self, redis_client: Redis):
        self._redis = redis_client
        self._ttl = _settings.cache_ttl_seconds

    async def get(self, student_id: StudentId) -> StudentAccountStatement | None:
        """Retrieve cached student account statement."""
        key = self._build_key(student_id)

        try:
            cached = await self._redis.get(key)

            if cached is None:
                logger.debug("cache_miss key=%s", key)
                return None

            logger.debug("cache_hit key=%s", key)
            return self._deserialize(cached)

        except RedisError as e:
            logger.warning(
                "cache_error_on_get key=%s error=%s error_type=%s",
                key,
                str(e),
                type(e).__name__,
            )
            return None  # Fail-open: treat as cache miss
        except (
            json.JSONDecodeError,
            KeyError,
            ValueError,
            InvalidStudentIdError,
            InvalidOperation,
        ) as e:
            logger.warning(
                "cache_deserialization_error key=%s error=%s",
                key,
                str(e),
            )
            return None  # Corrupted cache entry, treat as miss
    
    async def set(self, statement: StudentAccountStatement) -> None:
        """Cache student account statement with TTL."""
        key = self._build_key(statement.student_id)

        try:
            serialized = self._serialize(statement)
            await self._redis.set(key, serialized, ex=self._ttl)
            logger.debug("cache_set key=%s ttl=%s", key, self._ttl)

        except RedisError as e:
            logger.warning(
                "cache_error_on_set key=%s error=%s error_type=%s",
                key,
                str(e),
                type(e).__name__,
            )

    def _build_key(self, student_id: StudentId) -> str:
        """Build Redis key for student account statement."""
        return f"{self.KEY_PREFIX}:{student_id.value}"

    def _serialize(self, statement: StudentAccountStatement) -> str:
        """Serialize account statement to JSON string."""
        return json.dumps({
            "student_id": str(statement.student_id.value),
            "student_name": statement.student_name,
            "school_name": statement.school_name,
            "total_invoiced": str(statement.total_invoiced),
            "total_paid": str(statement.total_paid),
            "total_pending": str(statement.total_pending),
            "invoices_pending": statement.invoices_pending,
            "invoices_partially_paid": statement.invoices_partially_paid,
            "invoices_paid": statement.invoices_paid,
            "invoices_cancelled": statement.invoices_cancelled,
            "invoices_overdue": statement.invoices_overdue,
            "total_late_fees": str(statement.total_late_fees),
            "statement_date": statement.statement_date.isoformat(),
        })
    
    def _deserialize(self, json_str: str) -> StudentAccountStatement:
        """Deserialize JSON string to account statement."""
        data = json.loads(json_str)

        return StudentAccountStatement(
            student_id=StudentId.from_string(data["student_id"]),
            student_name=data["student_name"],
            school_name=data["school_name"],
            total_invoiced=Decimal(data["total_invoiced"]),
            total_paid=Decimal(data["total_paid"]),
            total_pending=Decimal(data["total_pending"]),
            invoices_pending=data["invoices_pending"],
            invoices_partially_paid=data["invoices_partially_paid"],
            invoices_paid=data["invoices_paid"],
            invoices_cancelled=data["invoices_cancelled"],
            invoices_overdue=data["invoices_overdue"],
            total_late_fees=Decimal(data["total_late_fees"]),
            statement_date=datetime.fromisoformat(data["statement_date"]),
        )
```

```python
# infrastructure/adapters/school_account_statement_cache/redis.py
from __future__ import annotations

import json
import logging
from datetime import datetime
from decimal import Decimal, InvalidOperation

from redis.asyncio import Redis
from redis.exceptions import RedisError

from mattilda_challenge.application.dtos import SchoolAccountStatement
from mattilda_challenge.application.ports import SchoolAccountStatementCache
from mattilda_challenge.config import get_settings
from mattilda_challenge.domain.exceptions import InvalidSchoolIdError
from mattilda_challenge.domain.value_objects import SchoolId

logger = logging.getLogger(__name__)
_settings = get_settings()


class RedisSchoolAccountStatementCache(SchoolAccountStatementCache):
    """
    Redis implementation of SchoolAccountStatementCache port.

    Same pattern as RedisStudentAccountStatementCache.
    """

    KEY_PREFIX = "mattilda:cache:v1:account_statement:school"

    def __init__(self, redis_client: Redis):
        self._redis = redis_client
        self._ttl = _settings.cache_ttl_seconds

    async def get(self, school_id: SchoolId) -> SchoolAccountStatement | None:
        """Retrieve cached school account statement."""
        key = self._build_key(school_id)

        try:
            cached = await self._redis.get(key)

            if cached is None:
                logger.debug("cache_miss key=%s", key)
                return None

            logger.debug("cache_hit key=%s", key)
            return self._deserialize(cached)

        except RedisError as e:
            logger.warning(
                "cache_error_on_get key=%s error=%s error_type=%s",
                key,
                str(e),
                type(e).__name__,
            )
            return None
        except (
            json.JSONDecodeError,
            KeyError,
            ValueError,
            InvalidSchoolIdError,
            InvalidOperation,
        ) as e:
            logger.warning(
                "cache_deserialization_error key=%s error=%s",
                key,
                str(e),
            )
            return None

    async def set(self, statement: SchoolAccountStatement) -> None:
        """Cache school account statement with TTL."""
        key = self._build_key(statement.school_id)

        try:
            serialized = self._serialize(statement)
            await self._redis.set(key, serialized, ex=self._ttl)
            logger.debug("cache_set key=%s ttl=%s", key, self._ttl)

        except RedisError as e:
            logger.warning(
                "cache_error_on_set key=%s error=%s error_type=%s",
                key,
                str(e),
                type(e).__name__,
            )

    def _build_key(self, school_id: SchoolId) -> str:
        """Build Redis key for school account statement."""
        return f"{self.KEY_PREFIX}:{school_id.value}"
    
    def _serialize(self, statement: SchoolAccountStatement) -> str:
        """Serialize account statement to JSON string."""
        return json.dumps({
            "school_id": str(statement.school_id.value),
            "school_name": statement.school_name,
            "total_students": statement.total_students,
            "active_students": statement.active_students,
            "total_invoiced": str(statement.total_invoiced),
            "total_paid": str(statement.total_paid),
            "total_pending": str(statement.total_pending),
            "invoices_pending": statement.invoices_pending,
            "invoices_partially_paid": statement.invoices_partially_paid,
            "invoices_paid": statement.invoices_paid,
            "invoices_overdue": statement.invoices_overdue,
            "invoices_cancelled": statement.invoices_cancelled,
            "total_late_fees": str(statement.total_late_fees),
            "statement_date": statement.statement_date.isoformat(),
        })
    
    def _deserialize(self, json_str: str) -> SchoolAccountStatement:
        """Deserialize JSON string to account statement."""
        data = json.loads(json_str)
        
        return SchoolAccountStatement(
            school_id=SchoolId.from_string(data["school_id"]),
            school_name=data["school_name"],
            total_students=data["total_students"],
            active_students=data["active_students"],
            total_invoiced=Decimal(data["total_invoiced"]),
            total_paid=Decimal(data["total_paid"]),
            total_pending=Decimal(data["total_pending"]),
            invoices_pending=data["invoices_pending"],
            invoices_partially_paid=data["invoices_partially_paid"],
            invoices_paid=data["invoices_paid"],
            invoices_overdue=data["invoices_overdue"],
            invoices_cancelled=data["invoices_cancelled"],
            total_late_fees=Decimal(data["total_late_fees"]),
            statement_date=datetime.fromisoformat(data["statement_date"]),
        )
```

#### 5.5 Null Cache Implementation (For Testing)

For unit tests and environments without Redis:

```python
# infrastructure/adapters/null_account_statement_cache.py
from __future__ import annotations

from mattilda_challenge.application.ports import (
    StudentAccountStatementCache,
    SchoolAccountStatementCache,
)
from mattilda_challenge.application.dtos import (
    StudentAccountStatement,
    SchoolAccountStatement,
)
from mattilda_challenge.domain.value_objects import StudentId, SchoolId


class NullStudentAccountStatementCache(StudentAccountStatementCache):
    """
    No-op cache implementation for testing or disabled cache scenarios.
    
    Always returns None (cache miss) and discards set operations.
    """
    
    async def get(self, student_id: StudentId) -> StudentAccountStatement | None:
        return None
    
    async def set(self, statement: StudentAccountStatement) -> None:
        pass  # No-op


class NullSchoolAccountStatementCache(SchoolAccountStatementCache):
    """No-op cache implementation for school account statements."""
    
    async def get(self, school_id: SchoolId) -> SchoolAccountStatement | None:
        return None
    
    async def set(self, statement: SchoolAccountStatement) -> None:
        pass
```

---

### 6. Use Case Integration

The cache is used in use cases following the **cache-aside pattern**:

```python
# application/use_cases/get_student_account_statement.py
from __future__ import annotations

from datetime import datetime

from mattilda_challenge.application.ports import StudentAccountStatementCache
from mattilda_challenge.application.dtos import StudentAccountStatement
from mattilda_challenge.domain.value_objects import StudentId
from mattilda_challenge.domain.exceptions import StudentNotFoundError
from mattilda_challenge.infrastructure.postgres.unit_of_work import UnitOfWork


class GetStudentAccountStatementUseCase:
    """
    Use case: Get student account statement with caching.
    
    Implements cache-aside pattern:
    1. Check cache
    2. On miss: compute from database, cache result
    3. Return statement
    """
    
    def __init__(self, cache: StudentAccountStatementCache):
        self._cache = cache
    
    async def execute(
        self,
        uow: UnitOfWork,
        student_id: StudentId,
        now: datetime,
    ) -> StudentAccountStatement:
        """
        Get student account statement.
        
        Args:
            uow: Unit of Work for database access
            student_id: Student identifier
            now: Current timestamp (for late fee calculation)
            
        Returns:
            Student account statement (from cache or freshly computed)
            
        Raises:
            StudentNotFoundError: If student doesn't exist
        """
        # Step 1: Check cache
        cached = await self._cache.get(student_id)
        if cached is not None:
            return cached
        
        # Step 2: Compute from database
        statement = await self._compute_statement(uow, student_id, now)
        
        # Step 3: Cache result (fire-and-forget, fail-open)
        await self._cache.set(statement)
        
        return statement
    
    async def _compute_statement(
        self,
        uow: UnitOfWork,
        student_id: StudentId,
        now: datetime,
    ) -> StudentAccountStatement:
        """
        Compute account statement from database.
        
        Delegates to repository for aggregate queries.
        """
        # Verify student exists
        student = await uow.students.get_by_id(student_id)
        if student is None:
            raise StudentNotFoundError(f"Student {student_id} not found")
        
        # Get school name
        school = await uow.schools.get_by_id(student.school_id)
        
        # Compute aggregates (delegates to repository)
        statement = await uow.students.get_account_statement(student_id, now)
        
        return statement
```

```python
# application/use_cases/get_school_account_statement.py
from __future__ import annotations

from datetime import datetime

from mattilda_challenge.application.ports import SchoolAccountStatementCache
from mattilda_challenge.application.dtos import SchoolAccountStatement
from mattilda_challenge.domain.value_objects import SchoolId
from mattilda_challenge.domain.exceptions import SchoolNotFoundError
from mattilda_challenge.infrastructure.postgres.unit_of_work import UnitOfWork


class GetSchoolAccountStatementUseCase:
    """
    Use case: Get school account statement with caching.
    
    Same cache-aside pattern as student account statement.
    """
    
    def __init__(self, cache: SchoolAccountStatementCache):
        self._cache = cache
    
    async def execute(
        self,
        uow: UnitOfWork,
        school_id: SchoolId,
        now: datetime,
    ) -> SchoolAccountStatement:
        """
        Get school account statement.
        
        Args:
            uow: Unit of Work for database access
            school_id: School identifier
            now: Current timestamp (for late fee calculation)
            
        Returns:
            School account statement (from cache or freshly computed)
            
        Raises:
            SchoolNotFoundError: If school doesn't exist
        """
        # Step 1: Check cache
        cached = await self._cache.get(school_id)
        if cached is not None:
            return cached
        
        # Step 2: Compute from database
        statement = await self._compute_statement(uow, school_id, now)
        
        # Step 3: Cache result
        await self._cache.set(statement)
        
        return statement
    
    async def _compute_statement(
        self,
        uow: UnitOfWork,
        school_id: SchoolId,
        now: datetime,
    ) -> SchoolAccountStatement:
        """Compute account statement from database."""
        # Verify school exists
        school = await uow.schools.get_by_id(school_id)
        if school is None:
            raise SchoolNotFoundError(f"School {school_id} not found")
        
        # Compute aggregates
        statement = await uow.schools.get_account_statement(school_id, now)
        
        return statement
```

---

### 7. Dependency Injection (FastAPI)

```python
# entrypoints/http/dependencies.py
from __future__ import annotations

from fastapi import Depends
from redis.asyncio import Redis

from mattilda_challenge.infrastructure.redis.client import get_redis_client
from mattilda_challenge.infrastructure.adapters import (
    RedisStudentAccountStatementCache,
    RedisSchoolAccountStatementCache,
)
from mattilda_challenge.application.ports import (
    StudentAccountStatementCache,
    SchoolAccountStatementCache,
)


async def get_student_account_statement_cache(
    redis: Redis = Depends(get_redis_client),
) -> StudentAccountStatementCache:
    """Provide StudentAccountStatementCache instance."""
    return RedisStudentAccountStatementCache(redis)


async def get_school_account_statement_cache(
    redis: Redis = Depends(get_redis_client),
) -> SchoolAccountStatementCache:
    """Provide SchoolAccountStatementCache instance."""
    return RedisSchoolAccountStatementCache(redis)
```

```python
# entrypoints/http/routes/students.py (account statement endpoint)
from fastapi import APIRouter, Depends

from mattilda_challenge.application.use_cases import GetStudentAccountStatementUseCase
from mattilda_challenge.application.ports import StudentAccountStatementCache
from mattilda_challenge.entrypoints.http.dependencies import (
    get_session,
    get_time_provider,
    get_student_account_statement_cache,
)

router = APIRouter(prefix="/students", tags=["Students"])


@router.get("/{id}/account-statement")
async def get_student_account_statement(
    id: str,
    session: AsyncSession = Depends(get_session),
    time_provider: TimeProvider = Depends(get_time_provider),
    cache: StudentAccountStatementCache = Depends(get_student_account_statement_cache),
):
    """Get student account statement (cached)."""
    async with UnitOfWork(session) as uow:
        student_id = StudentId.from_string(id)
        
        use_case = GetStudentAccountStatementUseCase(cache)
        statement = await use_case.execute(uow, student_id, time_provider.now())
        
        return AccountStatementMapper.to_student_response(statement)
```

---

### 8. Serialization: JSON with String Decimals

**Format:**
```json
{
  "student_id": "550e8400-e29b-41d4-a716-446655440000",
  "student_name": "Juan Pérez García",
  "school_name": "Colegio ABC",
  "total_invoiced": "4500.00",
  "total_paid": "1500.00",
  "total_pending": "3000.00",
  "invoices_pending": 1,
  "invoices_partially_paid": 1,
  "invoices_paid": 1,
  "invoices_cancelled": 0,
  "invoices_overdue": 1,
  "total_late_fees": "50.00",
  "statement_date": "2024-01-20T15:00:00+00:00"
}
```

**Key decisions:**

| Type | Serialization | Rationale |
|------|---------------|-----------|
| UUID | String (`"550e8400..."`) | Standard UUID string format |
| Decimal | String (`"4500.00"`) | Preserves precision (ADR-002 compliance) |
| datetime | ISO 8601 (`"2024-01-20T15:00:00+00:00"`) | Standard format, includes timezone |
| int | Native JSON number | No precision concerns for counts |

**Consistency with API**: This serialization matches the REST API response format (ADR-005), making debugging easier.

---

### 9. Failure Handling: Fail-Open

The cache implements **fail-open** behavior: on any Redis error, the system proceeds as if the cache doesn't exist.

**Behavior matrix:**

| Operation | Redis Available | Redis Unavailable |
|-----------|-----------------|-------------------|
| `get()` | Return cached value or None | Return None (log warning) |
| `set()` | Store in Redis | No-op (log warning) |

**Implementation pattern:**
```python
try:
    cached = await self._redis.get(key)
    return self._deserialize(cached)
except RedisError as e:
    logger.warning("cache_error key=%s error=%s", key, str(e))
    return None  # Fail-open: treat as cache miss
except (
    json.JSONDecodeError,
    KeyError,
    ValueError,
    InvalidStudentIdError,  # Domain exception for invalid UUID
    InvalidOperation,       # Decimal parsing error
) as e:
    logger.warning("cache_deserialization_error key=%s error=%s", key, str(e))
    return None  # Corrupted cache entry, treat as miss
```

**Note**: The implementation catches additional exceptions beyond basic JSON errors:
- `InvalidStudentIdError` / `InvalidSchoolIdError`: Raised when cached UUID is malformed
- `decimal.InvalidOperation`: Raised when cached decimal string is invalid

This provides more robust fail-open behavior for edge cases like corrupted cache entries.

**Rationale:**
- Cache is performance optimization, not critical path
- Database is always available as fallback
- Users experience slower response, not errors
- Simple implementation (no circuit breaker complexity)

---

### 10. Cache Warming: Lazy (On First Request)

Cache is populated **lazily** on first request (cache-aside pattern), not eagerly on startup.

**Rationale:**
- Simpler implementation (no startup job)
- No wasted cache entries for unused data
- Natural load distribution (requests warm cache gradually)
- Matches project scope (cache is "nice to have")

**Alternative considered (eager warming):** Pre-populating cache on startup would reduce latency for first requests, but adds complexity:
- Need to iterate all schools/students
- Startup time increases
- May cache data that's never requested

---

### 11. Docker Compose Configuration

```yaml
# docker-compose.yml
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://user:pass@db:5432/mattilda
      - REDIS_URL=redis://redis:6379/0
      - CACHE_TTL_SECONDS=300
    depends_on:
      - db
      - redis
  
  db:
    image: postgres:16
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=mattilda
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes  # Enable persistence

volumes:
  postgres_data:
  redis_data:
```

**Redis configuration notes:**
- `redis:7-alpine`: Minimal image, sufficient for caching
- `--appendonly yes`: Optional persistence (survives container restart)
- Default `maxmemory-policy`: `noeviction` (consider `allkeys-lru` for production)

---

### 12. Cache Invalidation Triggers (Documented, Not Implemented)

While we use TTL-only invalidation, it's important to document what events *would* invalidate cached data. This helps understand staleness scenarios and provides a roadmap if event-driven invalidation is added later.

**Student account statement invalidation triggers:**
| Event | Impact |
|-------|--------|
| Invoice created for student | `total_invoiced`, `invoices_pending` change |
| Invoice updated (amount, due_date) | Aggregates change |
| Invoice status changed | Status counts change |
| Invoice cancelled | `invoices_cancelled` increases |
| Payment recorded | `total_paid`, invoice status may change |
| Late fee accrual (time passing) | `total_late_fees` increases |

**School account statement invalidation triggers:**
| Event | Impact |
|-------|--------|
| Any student invoice/payment change | All aggregates may change |
| Student added to school | `total_students`, `active_students` change |
| Student status changed | `active_students` may change |
| Student removed from school | All aggregates may change |

**With TTL-only invalidation**: Changes are reflected within 5 minutes (maximum staleness).

---

## Consequences

### Positive

✅ **Reduced database load**: Account statement queries (expensive JOINs + late fee calculations) are cached  
✅ **Improved latency**: Cache hits return in ~1ms vs ~100-500ms from database  
✅ **Simple implementation**: TTL-only invalidation, no event infrastructure  
✅ **Fail-safe**: System works correctly without Redis (fail-open)  
✅ **Consistent architecture**: Follows ports/adapters pattern from existing ADRs  
✅ **Type-safe**: Domain-specific cache ports provide compile-time safety  
✅ **Testable**: Null cache implementation for unit tests  
✅ **Debuggable**: JSON serialization, readable cache keys  

### Negative

⚠️ **Staleness**: Data may be up to 5 minutes stale after writes  
⚠️ **Memory usage**: Cached statements consume Redis memory  
⚠️ **Additional dependency**: Redis must be running in production  
⚠️ **Late fee drift**: Cached `total_late_fees` may be slightly outdated (up to 5 minutes)  

### Trade-offs

| Aspect | Decision | Trade-off |
|--------|----------|-----------|
| Invalidation | TTL-only | Simple but stale vs. Complex but fresh |
| Scope | Account statements only | Focused benefit vs. Broader optimization |
| Serialization | JSON | Human-readable vs. Compact/fast |
| Failure mode | Fail-open | Availability vs. Consistency |

---

## Alternatives Considered

### 1. No Caching

**Alternative:** Don't implement caching at all.

**Rejected because:**
- Account statement queries are expensive (multiple JOINs + late fee loop)
- Challenge explicitly mentions cache as bonus points
- Demonstrates understanding of caching patterns

### 2. Event-Driven Invalidation

**Alternative:** Invalidate cache immediately when data changes.

**Rejected because:**
- Significantly more complex (need to track affected keys)
- Requires modifying all write use cases
- Adds failure modes (missed invalidation events)
- TTL-only is sufficient for dashboard/reporting use case
- Challenge scope doesn't justify complexity

### 3. Generic Cache Port

**Alternative:** Single `Cache[T]` generic port for all cached types.

**Rejected because:**
- Less type-safe (easy to cache wrong type)
- Serialization logic becomes caller's responsibility
- Domain-specific ports are clearer and safer

### 4. In-Memory Cache (No Redis)

**Alternative:** Use Python dict or `cachetools` for in-memory caching.

**Rejected because:**
- Doesn't scale to multiple backend instances
- Lost on container restart
- Challenge already includes Redis in tech stack
- Redis demonstrates real-world caching pattern

### 5. Cache Decorator Pattern

**Alternative:** Use `@cached(ttl=300)` decorator on use case methods.

**Rejected because:**
- Hides caching logic (magic behavior)
- Harder to test (decorator interception)
- Inconsistent with explicit dependency injection pattern
- Cache-aside in use case is more explicit

---

## Implementation Checklist

### Phase 1: Infrastructure Setup
- [x] Add `redis-py` to dependencies in `pyproject.toml`
- [x] Add Redis service to `docker-compose.yml`
- [x] Create `config.py` entries for `REDIS_URL` and `CACHE_TTL_SECONDS`
- [x] Create `infrastructure/redis/client.py` with connection pool
- [ ] Add Redis pool cleanup to FastAPI lifespan handler

### Phase 2: Ports and Adapters
- [x] Create `application/ports/student_account_statement_cache.py` with ABC interface
- [x] Create `application/ports/school_account_statement_cache.py` with ABC interface
- [x] Create `infrastructure/adapters/student_account_statement_cache/redis.py`
- [x] Create `infrastructure/adapters/school_account_statement_cache/redis.py`
- [x] Create `infrastructure/adapters/student_account_statement_cache/null.py` for testing
- [x] Create `infrastructure/adapters/school_account_statement_cache/null.py` for testing
- [x] Update `infrastructure/adapters/__init__.py` exports
- [x] Update `application/ports/__init__.py` exports

### Phase 3: Use Case Integration
- [ ] Update `GetStudentAccountStatementUseCase` to accept cache parameter
- [ ] Update `GetSchoolAccountStatementUseCase` to accept cache parameter
- [ ] Implement cache-aside pattern in both use cases

### Phase 4: Dependency Injection
- [ ] Create `get_student_account_statement_cache()` in `dependencies.py`
- [ ] Create `get_school_account_statement_cache()` in `dependencies.py`
- [ ] Update account statement route handlers to inject cache

### Phase 5: Testing
- [x] Unit tests for cache adapters (mock Redis client)
- [ ] Unit tests for use cases with null cache (verify fallback)
- [x] Integration tests with real Redis (verify TTL behavior)
- [x] Test fail-open behavior (Redis unavailable scenario)

### Phase 6: Documentation
- [x] Update README with Redis setup instructions
- [x] Add cache configuration to environment variables documentation
- [x] Document cache inspection commands (Makefile: `redis-cli`, `redis-keys`, `redis-get`, `redis-ttl`, `redis-clear`)

---

## Testing Strategy

### Unit Tests

**Cache Adapter Tests:**
```python
# tests/unit/infrastructure/adapters/test_student_account_statement_cache.py

import pytest
from unittest.mock import AsyncMock, MagicMock
from redis.exceptions import ConnectionError

from mattilda_challenge.infrastructure.adapters import (
    RedisStudentAccountStatementCache
)


@pytest.fixture
def mock_redis():
    """Mock Redis client."""
    return AsyncMock()


@pytest.fixture
def cache(mock_redis):
    """Cache adapter with mock Redis."""
    return RedisStudentAccountStatementCache(mock_redis)


async def test_get_returns_none_on_cache_miss(cache, mock_redis):
    """Test get returns None when key not found."""
    mock_redis.get.return_value = None
    
    result = await cache.get(StudentId.generate())
    
    assert result is None


async def test_get_returns_deserialized_statement_on_hit(cache, mock_redis):
    """Test get deserializes cached JSON correctly."""
    cached_json = '{"student_id": "...", "total_invoiced": "1500.00", ...}'
    mock_redis.get.return_value = cached_json
    
    result = await cache.get(StudentId.from_string("..."))
    
    assert isinstance(result, StudentAccountStatement)
    assert result.total_invoiced == Decimal("1500.00")


async def test_get_returns_none_on_redis_error(cache, mock_redis):
    """Test fail-open behavior on Redis connection error."""
    mock_redis.get.side_effect = ConnectionError("Redis unavailable")
    
    result = await cache.get(StudentId.generate())
    
    assert result is None  # Fail-open, not exception


async def test_set_calls_redis_with_ttl(cache, mock_redis):
    """Test set stores serialized statement with TTL."""
    statement = StudentAccountStatement(...)
    
    await cache.set(statement)
    
    mock_redis.set.assert_called_once()
    call_args = mock_redis.set.call_args
    assert call_args.kwargs["ex"] == 300  # TTL


async def test_set_does_not_raise_on_redis_error(cache, mock_redis):
    """Test fail-open behavior on set error."""
    mock_redis.set.side_effect = ConnectionError("Redis unavailable")
    statement = StudentAccountStatement(...)
    
    # Should not raise
    await cache.set(statement)
```

**Use Case Tests (with Null Cache):**
```python
# tests/unit/application/use_cases/test_get_student_account_statement.py

async def test_use_case_computes_from_database_on_cache_miss():
    """Test use case falls back to database when cache misses."""
    null_cache = NullStudentAccountStatementCache()
    mock_uow = create_mock_uow_with_student()
    
    use_case = GetStudentAccountStatementUseCase(null_cache)
    result = await use_case.execute(mock_uow, student_id, now)
    
    assert result is not None
    # Verify database was queried
    mock_uow.students.get_account_statement.assert_called_once()
```

### Integration Tests

```python
# tests/integration/test_cache_integration.py

@pytest.mark.integration
async def test_account_statement_caching_roundtrip(redis_client, db_session):
    """Test full caching flow: miss → compute → cache → hit."""
    cache = RedisStudentAccountStatementCache(redis_client)
    student_id = StudentId.generate()
    
    # First request: cache miss
    result1 = await cache.get(student_id)
    assert result1 is None
    
    # Simulate computation and caching
    statement = StudentAccountStatement(student_id=student_id, ...)
    await cache.set(statement)
    
    # Second request: cache hit
    result2 = await cache.get(student_id)
    assert result2 is not None
    assert result2.student_id == student_id


@pytest.mark.integration
async def test_cache_expires_after_ttl(redis_client):
    """Test cache entry expires after TTL."""
    # Configure short TTL for test
    cache = RedisStudentAccountStatementCache(redis_client)
    cache._ttl = 1  # 1 second TTL
    
    statement = StudentAccountStatement(...)
    await cache.set(statement)
    
    # Immediate read: hit
    result1 = await cache.get(statement.student_id)
    assert result1 is not None
    
    # Wait for expiry
    await asyncio.sleep(1.5)
    
    # After TTL: miss
    result2 = await cache.get(statement.student_id)
    assert result2 is None
```

---

## Monitoring and Debugging

### Redis CLI Commands

```bash
# List all cache keys
redis-cli KEYS "mattilda:cache:*"

# Get specific cached statement
redis-cli GET "mattilda:cache:v1:account_statement:student:550e8400-..."

# Check TTL remaining
redis-cli TTL "mattilda:cache:v1:account_statement:student:550e8400-..."

# Delete specific cache entry (manual invalidation)
redis-cli DEL "mattilda:cache:v1:account_statement:student:550e8400-..."

# Clear all cache entries (schema version bump simulation)
redis-cli KEYS "mattilda:cache:v1:*" | xargs redis-cli DEL

# Monitor cache operations in real-time
redis-cli MONITOR | grep "mattilda:cache"
```

### Logging

Cache adapters log the following events:

| Event | Level | Fields |
|-------|-------|--------|
| Cache hit | DEBUG | `key` |
| Cache miss | DEBUG | `key` |
| Cache set | DEBUG | `key`, `ttl` |
| Redis error (get) | WARNING | `key`, `error`, `error_type` |
| Redis error (set) | WARNING | `key`, `error`, `error_type` |
| Deserialization error | WARNING | `key`, `error` |

**Note**: Log statements use stdlib `logging` with %-formatting style (e.g., `logger.debug("cache_hit key=%s", key)`). This is compatible with all logging configurations and provides lazy string interpolation for better performance when log level is disabled.

---

## Related ADRs

- **[ADR-001](ADR-001-project-initialization.md)**: Project initialization (Clean Architecture, ABC ports)
- **[ADR-002](ADR-002-domain-model.md)**: Domain model (account statement structure)
- **[ADR-004](ADR-004-postgresql-persistence.md)**: PostgreSQL persistence (account statement repository)
- **[ADR-005](ADR-005-rest-api-design.md)**: REST API design (account statement endpoints)

---

## Future Enhancements

If more sophisticated caching is needed in the future:

1. **Event-driven invalidation**: Publish events from write use cases, subscribe in cache layer
2. **Cache warming**: Pre-populate cache for high-traffic schools on startup
3. **Distributed locking**: Prevent thundering herd with Redis SETNX
4. **Cache metrics**: Track hit rate, latency, memory usage with Prometheus
5. **Multi-tier caching**: Add local in-memory cache (L1) in front of Redis (L2)
6. **Compression**: Compress large cached payloads with zlib/lz4

These enhancements are **out of scope** for the current challenge but documented for future reference.
