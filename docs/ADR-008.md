# ADR-008: Observability Strategy

## Status

Implemented

## Context

The Mattilda Challenge system requires observability capabilities to monitor application health, debug issues, and understand system behavior. Observability encompasses the "three pillars": **logs**, **metrics**, and **traces**.

### Project Context

The Mattilda Challenge PDF lists observability as an **optional extra** that "adds points":

> **EXTRAS (no obligatorios, pero suman puntos)**
> - Estrategias sencillas de **observabilidad**: logs, métricas, health checks.

Given this context and the 48-hour time constraint, the observability implementation should be:
- **Simple**: Production-ready patterns without over-engineering
- **Focused**: Logs, metrics, and health checks (no distributed tracing)
- **Local-first**: Designed for Docker Compose, not Kubernetes

### Scope Boundaries

**In Scope (this ADR):**
- Structured logging with request correlation
- Health check endpoints with dependency status
- Prometheus metrics endpoint
- Request ID middleware

**Out of Scope (48-hour challenge):**
- **Authentication/Authorization** — Adds significant complexity, deferred
- **Frontend** — Backend-only challenge
- **Distributed Tracing (OpenTelemetry/Jaeger)** — More relevant for microservices architectures
- **Log Aggregation Infrastructure (ELK/Loki)** — Logs go to stdout per 12-factor app
- **Kubernetes-specific probes** — Running locally with Docker Compose only
- **Prometheus/Grafana server setup** — `/metrics` endpoint exposed, scraping is infrastructure concern
- **Alerting** — Requires external Prometheus/Alertmanager setup

### Related ADRs

- **[ADR-001](ADR-001-project-initialization.md)**: Clean Architecture, ABC ports, infrastructure isolation
- **[ADR-005](ADR-005-rest-api-design.md)**: REST API design, middleware patterns
- **[ADR-006](ADR-006-redis-caching.md)**: Redis caching (logs cache hits/misses)

---

## Decision

### 1. Structured Logging with structlog

We use **structlog** for structured logging with JSON output in production and colored console output in development.

**Why structlog:**
- Native JSON output for machine parsing (production)
- Pretty colored output for humans (development)
- Context binding (request_id propagates automatically)
- Zero monkey-patching, explicit configuration
- Industry standard for Python structured logging

**Configuration Strategy:**

| Environment | Output Format | Timestamp | Use Case |
|-------------|---------------|-----------|----------|
| Development (`DEBUG=true`) | Colored console | Local time | Human readability |
| Production (`DEBUG=false`) | JSON lines | ISO 8601 UTC | Log aggregation |

```python
# Example log output (production JSON)
{
  "timestamp": "2024-01-20T15:00:00.000000Z",
  "level": "info",
  "event": "invoice_created",
  "request_id": "abc-123-def",
  "student_id": "550e8400-e29b-41d4-a716-446655440000",
  "amount": "150.00",
  "module": "use_cases.create_invoice",
  "lineno": 42
}
```

**Logging Principles (from 12-factor app):**
- Log to unbuffered stdout
- Let external tools handle aggregation, rotation, shipping
- One log entry per significant event (avoid verbose logging)
- Include context (request_id, entity_id) for correlation

**What NOT to Log (production hygiene):**
- ❌ Request/response bodies (size, potential PII)
- ❌ Personally Identifiable Information (emails, names, addresses)
- ❌ High-cardinality fields that could explode log volume
- ❌ Secrets, tokens, or credentials (even partial)
- ❌ Raw SQL queries with parameter values

---

### 2. Technology Stack

| Component | Choice | Rationale |
|-----------|--------|-----------|
| Structured Logging | `structlog` | Industry standard, clean API, JSON/console dual mode |
| Metrics | `prometheus-fastapi-instrumentator` | Zero-config FastAPI integration, standard metrics |
| Health Checks | Manual implementation | Simple, no extra dependencies, full control |
| Request ID | Custom middleware + `contextvars` | Python 3.7+ standard, thread-safe |

**Dependencies to add:**

```toml
# pyproject.toml
dependencies = [
    # ... existing
    "structlog>=24.1.0",
    "prometheus-fastapi-instrumentator>=7.0.0",
]
```

---

### 3. Request ID Middleware

Every request receives a unique identifier for correlation across logs and responses.

**Header Standard:** `X-Request-ID`
- If client provides header: use it (enables end-to-end tracing)
- If not provided: generate UUID4

**Storage:** Python `contextvars` for async-safe, request-scoped access.

```python
# infrastructure/observability/request_id.py
from __future__ import annotations

import uuid
from contextvars import ContextVar
from typing import Callable

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response

# Request-scoped context variable
request_id_ctx: ContextVar[str] = ContextVar("request_id", default="")


def get_request_id() -> str:
    """Get current request ID from context."""
    return request_id_ctx.get()


class RequestIdMiddleware(BaseHTTPMiddleware):
    """
    Middleware to extract or generate X-Request-ID header.
    
    - Extracts X-Request-ID from incoming request headers
    - Generates UUID4 if not present
    - Stores in contextvars for access anywhere in request lifecycle
    - Adds to response headers for client correlation
    """
    
    async def dispatch(
        self, request: Request, call_next: Callable
    ) -> Response:
        # Extract or generate request ID
        request_id = request.headers.get("X-Request-ID")
        if not request_id:
            request_id = str(uuid.uuid4())
        
        # Store in context for access by loggers
        token = request_id_ctx.set(request_id)
        
        try:
            response = await call_next(request)
            # Echo request ID in response headers
            response.headers["X-Request-ID"] = request_id
            return response
        finally:
            request_id_ctx.reset(token)
```

---

### 4. Structured Logging Configuration

```python
# infrastructure/observability/logging.py
from __future__ import annotations

import logging
import sys

import structlog

from mattilda_challenge.infrastructure.observability.request_id import get_request_id


def add_request_id(
    logger: structlog.types.WrappedLogger,
    method_name: str,
    event_dict: structlog.types.EventDict,
) -> structlog.types.EventDict:
    """Processor to add request_id to every log entry."""
    request_id = get_request_id()
    if request_id:
        event_dict["request_id"] = request_id
    return event_dict


def configure_logging(*, debug: bool = False) -> None:
    """
    Configure structlog for the application.
    
    Args:
        debug: If True, use colored console output. If False, use JSON.
    """
    # Shared processors for all environments
    shared_processors: list[structlog.types.Processor] = [
        structlog.contextvars.merge_contextvars,
        add_request_id,
        structlog.processors.add_log_level,
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.TimeStamper(fmt="iso", utc=True),
        structlog.processors.CallsiteParameterAdder(
            [
                structlog.processors.CallsiteParameter.MODULE,
                structlog.processors.CallsiteParameter.LINENO,
            ]
        ),
    ]
    
    if debug:
        # Development: colored console output
        processors = shared_processors + [
            structlog.dev.ConsoleRenderer(colors=True),
        ]
    else:
        # Production: JSON output
        processors = shared_processors + [
            structlog.processors.EventRenamer("message"),
            structlog.processors.dict_tracebacks,
            structlog.processors.JSONRenderer(),
        ]
    
    structlog.configure(
        processors=processors,
        wrapper_class=structlog.make_filtering_bound_logger(
            logging.DEBUG if debug else logging.INFO
        ),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )


def get_logger(name: str | None = None) -> structlog.stdlib.BoundLogger:
    """
    Get a configured structlog logger.
    
    Args:
        name: Optional logger name (typically __name__)
        
    Returns:
        Configured bound logger
    """
    return structlog.get_logger(name)
```

**Usage in Application Code:**

```python
# In use cases
from mattilda_challenge.infrastructure.observability.logging import get_logger

logger = get_logger(__name__)

class CreateInvoiceUseCase:
    async def execute(self, request: CreateInvoiceRequest) -> Invoice:
        logger.info(
            "creating_invoice",
            student_id=str(request.student_id),
            amount=str(request.amount),
        )
        
        # ... business logic ...
        
        logger.info(
            "invoice_created",
            invoice_id=str(invoice.id),
            student_id=str(invoice.student_id),
        )
        return invoice
```

---

### 5. Health Check Endpoints

We implement health checks manually for full control and minimal dependencies.

**Endpoint Design:**

| Endpoint | Purpose | Checks | Response Time |
|----------|---------|--------|---------------|
| `GET /health` | Combined health status | App + all dependencies | <100ms |
| `GET /health/live` | Liveness (is process alive?) | App responds | <10ms |
| `GET /health/ready` | Readiness (can handle traffic?) | DB + Redis connected | <100ms |

**Semantic Distinction:**
- **`/health`** is **diagnostic** — intended for humans, monitoring dashboards, and debugging. Returns detailed dependency information.
- **`/health/ready`** is **traffic-gating** — intended for orchestrators (Kubernetes, load balancers) to decide whether to route traffic. Same checks as `/health`, but semantically indicates "ready to accept requests".
- **`/health/live`** is **process-level** — only confirms the application process is running. Does NOT check external dependencies (by design).

**Note on Kubernetes Probes:** While we implement `/health/live` and `/health/ready` endpoints following Kubernetes conventions, the actual probe configuration (periodSeconds, timeoutSeconds, failureThreshold) is a Kubernetes infrastructure concern and out of scope for this local Docker Compose deployment.

#### 5.1 Health Check Response Schema

```python
# entrypoints/http/schemas/health.py
from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Literal

from pydantic import BaseModel, Field


class HealthStatus(str, Enum):
    """Health check status values."""
    HEALTHY = "healthy"
    UNHEALTHY = "unhealthy"
    DEGRADED = "degraded"  # Optional: some dependencies down but app functional


class DependencyHealth(BaseModel):
    """Health status of a single dependency."""
    status: HealthStatus
    latency_ms: float | None = Field(
        default=None,
        description="Response time in milliseconds",
    )
    error: str | None = Field(
        default=None,
        description="Error message if unhealthy",
    )


class HealthResponse(BaseModel):
    """
    Health check response.
    
    Example:
        {
            "status": "healthy",
            "version": "1.0.0",
            "timestamp": "2024-01-20T15:00:00Z",
            "dependencies": {
                "database": {"status": "healthy", "latency_ms": 5.2},
                "redis": {"status": "healthy", "latency_ms": 1.8}
            }
        }
    """
    status: HealthStatus
    version: str = Field(description="Application version")
    timestamp: datetime = Field(description="Check timestamp (UTC)")
    dependencies: dict[str, DependencyHealth] = Field(
        default_factory=dict,
        description="Status of external dependencies",
    )
    
    model_config = {
        "json_schema_extra": {
            "example": {
                "status": "healthy",
                "version": "1.0.0",
                "timestamp": "2024-01-20T15:00:00Z",
                "dependencies": {
                    "database": {"status": "healthy", "latency_ms": 5.2},
                    "redis": {"status": "healthy", "latency_ms": 1.8},
                },
            }
        }
    }


class LivenessResponse(BaseModel):
    """Simple liveness response."""
    status: Literal["alive"] = "alive"
```

#### 5.2 Health Check Implementation

```python
# entrypoints/http/routes/health.py
from __future__ import annotations

import time
from datetime import datetime, timezone

from fastapi import APIRouter, Depends, Response, status
from redis.asyncio import Redis
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from mattilda_challenge.config import get_settings
from mattilda_challenge.entrypoints.http.dependencies import (
    get_session,
    get_redis_client,
)
from mattilda_challenge.entrypoints.http.schemas.health import (
    DependencyHealth,
    HealthResponse,
    HealthStatus,
    LivenessResponse,
)
from mattilda_challenge.infrastructure.observability.logging import get_logger

router = APIRouter(tags=["Health"])
logger = get_logger(__name__)


async def check_database(session: AsyncSession) -> DependencyHealth:
    """Check database connectivity."""
    start = time.perf_counter()
    try:
        await session.execute(text("SELECT 1"))
        latency_ms = (time.perf_counter() - start) * 1000
        return DependencyHealth(
            status=HealthStatus.HEALTHY,
            latency_ms=round(latency_ms, 2),
        )
    except Exception as e:
        logger.warning("database_health_check_failed", error=str(e))
        return DependencyHealth(
            status=HealthStatus.UNHEALTHY,
            error=str(e),
        )


async def check_redis(redis: Redis) -> DependencyHealth:
    """Check Redis connectivity."""
    start = time.perf_counter()
    try:
        await redis.ping()
        latency_ms = (time.perf_counter() - start) * 1000
        return DependencyHealth(
            status=HealthStatus.HEALTHY,
            latency_ms=round(latency_ms, 2),
        )
    except Exception as e:
        logger.warning("redis_health_check_failed", error=str(e))
        return DependencyHealth(
            status=HealthStatus.UNHEALTHY,
            error=str(e),
        )


@router.get(
    "/health",
    response_model=HealthResponse,
    summary="Health check with dependency status",
    description="Returns application health status including all dependencies.",
)
async def health_check(
    response: Response,
    session: AsyncSession = Depends(get_session),
    redis: Redis = Depends(get_redis_client),
) -> HealthResponse:
    """
    Combined health check endpoint.
    
    Checks:
    - Database connectivity (PostgreSQL)
    - Cache connectivity (Redis)
    
    Returns 200 if all healthy, 503 if any dependency is unhealthy.
    """
    settings = get_settings()
    
    # Check all dependencies
    db_health = await check_database(session)
    redis_health = await check_redis(redis)
    
    dependencies = {
        "database": db_health,
        "redis": redis_health,
    }
    
    # Determine overall status
    all_healthy = all(
        dep.status == HealthStatus.HEALTHY
        for dep in dependencies.values()
    )
    overall_status = HealthStatus.HEALTHY if all_healthy else HealthStatus.UNHEALTHY
    
    # Set HTTP status code based on health
    if overall_status != HealthStatus.HEALTHY:
        response.status_code = status.HTTP_503_SERVICE_UNAVAILABLE
    
    return HealthResponse(
        status=overall_status,
        version=settings.app_version,
        timestamp=datetime.now(timezone.utc),
        dependencies=dependencies,
    )


@router.get(
    "/health/live",
    response_model=LivenessResponse,
    summary="Liveness probe",
    description="Simple check that the application process is running.",
)
async def liveness() -> LivenessResponse:
    """
    Liveness probe endpoint.
    
    Returns 200 if the application is running. Used by orchestrators
    to determine if the process should be restarted.
    
    Note: Does NOT check external dependencies (by design).
    """
    return LivenessResponse()


@router.get(
    "/health/ready",
    response_model=HealthResponse,
    summary="Readiness probe",
    description="Check if the application is ready to receive traffic.",
)
async def readiness(
    response: Response,
    session: AsyncSession = Depends(get_session),
    redis: Redis = Depends(get_redis_client),
) -> HealthResponse:
    """
    Readiness probe endpoint.
    
    Returns 200 if the application can handle requests (all dependencies
    are available). Returns 503 if not ready.
    
    Note: Same checks as /health, but semantically indicates "can accept traffic".
    """
    return await health_check(response, session, redis)
```

---

### 6. Prometheus Metrics

We use `prometheus-fastapi-instrumentator` for automatic HTTP metrics with minimal configuration.

#### 6.1 Default Metrics (Out of the Box)

| Metric | Type | Description |
|--------|------|-------------|
| `http_request_duration_seconds` | Histogram | Request latency by method, path, status |
| `http_requests_total` | Counter | Total requests by method, path, status |
| `http_request_size_bytes` | Summary | Request body size |
| `http_response_size_bytes` | Summary | Response body size |
| `http_requests_in_progress` | Gauge | Currently processing requests |

#### 6.2 Configuration

```python
# infrastructure/observability/metrics.py
from __future__ import annotations

from prometheus_fastapi_instrumentator import Instrumentator, metrics
from fastapi import FastAPI


def setup_metrics(app: FastAPI) -> Instrumentator:
    """
    Configure Prometheus metrics for FastAPI application.
    
    Args:
        app: FastAPI application instance
        
    Returns:
        Configured instrumentator (for testing access)
    """
    instrumentator = Instrumentator(
        should_group_status_codes=True,  # Group 2xx, 3xx, etc.
        should_ignore_untemplated=True,  # Ignore unmatched routes
        should_respect_env_var=True,     # ENABLE_METRICS env var
        should_instrument_requests_inprogress=True,
        excluded_handlers=[
            "/health",
            "/health/live",
            "/health/ready",
            "/metrics",
            "/docs",
            "/redoc",
            "/openapi.json",
        ],
        inprogress_name="http_requests_in_progress",
        inprogress_labels=True,
    )
    
    # Add default metrics
    instrumentator.add(
        metrics.default(
            metric_namespace="mattilda",
            metric_subsystem="api",
        )
    )
    
    # Instrument app and expose /metrics endpoint
    instrumentator.instrument(app).expose(
        app,
        endpoint="/metrics",
        include_in_schema=False,  # Hide from OpenAPI docs
        should_gzip=True,
    )
    
    return instrumentator
```

#### 6.3 Custom Business Metrics (Optional Enhancement)

For bonus points, we can add domain-specific metrics:

```python
# infrastructure/observability/business_metrics.py
from __future__ import annotations

from prometheus_client import Counter, Histogram

# Invoice metrics
INVOICES_CREATED = Counter(
    "mattilda_invoices_created_total",
    "Total number of invoices created",
    ["school_id"],
)

PAYMENTS_RECORDED = Counter(
    "mattilda_payments_recorded_total",
    "Total number of payments recorded",
)

# Cache metrics (complements ADR-006)
CACHE_OPERATIONS = Counter(
    "mattilda_cache_operations_total",
    "Cache operations by type and result",
    ["cache_type", "operation", "result"],  # e.g., student_statement, get, hit
)

# Late fee calculations
LATE_FEE_CALCULATIONS = Histogram(
    "mattilda_late_fee_calculation_seconds",
    "Time spent calculating late fees",
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0],
)
```

**Note:** Business metrics are optional for this challenge. The default HTTP metrics from `prometheus-fastapi-instrumentator` are sufficient to demonstrate observability competence.

---

### 7. Application Integration

#### 7.1 FastAPI Lifespan Handler

```python
# entrypoints/http/app.py
from __future__ import annotations

from contextlib import asynccontextmanager

from fastapi import FastAPI

from mattilda_challenge.config import get_settings
from mattilda_challenge.infrastructure.observability.logging import configure_logging
from mattilda_challenge.infrastructure.observability.metrics import setup_metrics
from mattilda_challenge.infrastructure.observability.request_id import RequestIdMiddleware
from mattilda_challenge.entrypoints.http.routes import health


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler."""
    settings = get_settings()
    
    # Configure logging
    configure_logging(debug=settings.debug)
    
    logger = get_logger(__name__)
    logger.info(
        "application_starting",
        version=settings.app_version,
        environment="development" if settings.debug else "production",
    )
    
    yield
    
    logger.info("application_shutting_down")


def create_app() -> FastAPI:
    """Create and configure FastAPI application."""
    settings = get_settings()
    
    app = FastAPI(
        title="Mattilda Challenge API",
        version=settings.app_version,
        lifespan=lifespan,
    )
    
    # Add middleware (order matters: outermost first)
    app.add_middleware(RequestIdMiddleware)
    
    # Setup metrics (must be after middleware)
    setup_metrics(app)
    
    # Register routes
    app.include_router(health.router)
    # ... other routers
    
    return app
```

#### 7.2 Project Structure

```
src/mattilda_challenge/
├── infrastructure/
│   └── observability/           # NEW: Observability module
│       ├── __init__.py
│       ├── logging.py           # structlog configuration
│       ├── metrics.py           # Prometheus setup
│       ├── request_id.py        # Request ID middleware
│       └── business_metrics.py  # Optional: domain metrics
├── entrypoints/
│   └── http/
│       ├── app.py               # MODIFIED: Add observability setup
│       ├── schemas/
│       │   └── health.py        # NEW: Health check DTOs
│       └── routes/
│           └── health.py        # NEW: Health check endpoints
```

---

### 8. Configuration

```python
# config.py (additions)
from pydantic_settings import BaseSettings


class Settings(BaseSettings):
    # ... existing settings ...
    
    # Observability
    app_version: str = "1.0.0"
    debug: bool = False  # Controls log format (JSON vs console)
    enable_metrics: bool = True
    
    model_config = {
        "env_file": ".env",
    }
```

```bash
# .env.example (additions)
APP_VERSION=1.0.0
DEBUG=false
ENABLE_METRICS=true
```

**Note:** The metrics namespace (`mattilda`) is hardcoded in `metrics.py` rather than configurable. This is intentional — changing the namespace would break existing Prometheus queries and dashboards, so it should require a code change and review, not just an environment variable flip.

---

### 9. Docker Compose Integration

```yaml
# docker-compose.yml (health check configuration)
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DEBUG=false
      - ENABLE_METRICS=true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
```

**Why `/health/live` instead of `/health`?**
Using the liveness endpoint for Docker healthcheck avoids blocking container startup due to transient database or Redis unavailability. The `depends_on` with `service_healthy` already ensures dependencies are up before the API starts. The liveness check confirms the FastAPI process itself is responsive.

**Note:** The `healthcheck` in Docker Compose uses the simple `/health/live` endpoint. This is appropriate for local development. In a Kubernetes environment, separate liveness and readiness probes would be configured in the deployment manifest.

---

## Consequences

### Positive

✅ **Structured logging**: JSON logs in production enable log aggregation and searching  
✅ **Request correlation**: `request_id` links all logs for a single request  
✅ **Dependency visibility**: Health checks expose database and Redis status  
✅ **Industry-standard metrics**: Prometheus format compatible with any monitoring stack  
✅ **Development experience**: Colored console logs improve local debugging  
✅ **12-factor compliance**: Logs to stdout, config via environment variables  
✅ **Minimal dependencies**: Only `structlog` and `prometheus-fastapi-instrumentator`  
✅ **Production-ready patterns**: Can scale to Kubernetes without code changes  

### Negative

⚠️ **Log volume**: Structured logging adds overhead (mitigated by log level filtering)  
⚠️ **Metric cardinality**: High-cardinality labels can cause memory issues (mitigated by excluding dynamic paths)  
⚠️ **No distributed tracing**: Cannot trace requests across services (acceptable for monolith)  
⚠️ **Infrastructure burden**: Metrics endpoint requires Prometheus server to be useful  

### Trade-offs

| Aspect | Decision | Trade-off |
|--------|----------|-----------|
| Log format | JSON (prod) / Console (dev) | Machine-readable vs. Human-readable |
| Metrics library | prometheus-fastapi-instrumentator | Convention over configuration |
| Health checks | Manual implementation | Control vs. Convenience |
| Tracing | Not implemented | Simplicity vs. Deep visibility |

---

## Alternatives Considered

### 1. Python stdlib logging Only

**Alternative:** Use Python's built-in `logging` module without structlog.

**Rejected because:**
- Requires significant configuration for JSON output
- No built-in context binding (request_id propagation)
- Less readable development output
- structlog is industry standard for structured logging

### 2. Loguru Instead of structlog

**Alternative:** Use `loguru` for simpler configuration.

**Rejected because:**
- Less control over output format
- Global state (singleton logger)
- structlog's processor pipeline is more flexible
- structlog integrates better with stdlib logging

### 3. OpenTelemetry for Everything

**Alternative:** Use OpenTelemetry SDK for logs, metrics, and traces.

**Rejected because:**
- Significantly more complex setup
- Requires collector infrastructure
- Overkill for a single-service application
- 48-hour time constraint doesn't justify complexity

### 4. fastapi-health or fastapi-healthchecks Library

**Alternative:** Use a third-party library for health checks.

**Rejected because:**
- Adds dependency for minimal functionality
- Manual implementation is straightforward (~100 lines)
- Full control over response format and checks
- Demonstrates understanding of health check patterns

### 5. Custom Prometheus Metrics Only (No Instrumentator)

**Alternative:** Write Prometheus metrics manually using `prometheus_client`.

**Rejected because:**
- prometheus-fastapi-instrumentator provides sensible defaults
- Manual implementation requires more code
- Instrumentator handles middleware integration automatically
- Can still add custom metrics alongside default ones

---

## Future Enhancements

If the application evolves beyond the challenge scope:

1. **Distributed Tracing (OpenTelemetry)**
   - Add `opentelemetry-instrumentation-fastapi`
   - Export traces to Jaeger or Tempo
   - Correlate traces with logs via trace_id

2. **Log Aggregation**
   - Deploy Loki or Elasticsearch
   - Configure Promtail/Filebeat to ship logs
   - Create Grafana dashboards for log exploration

3. **Prometheus/Grafana Stack**
   - Deploy Prometheus server to scrape `/metrics`
   - Create Grafana dashboards for HTTP metrics
   - Configure alerting rules for SLOs

4. **Application Performance Monitoring (APM)**
   - Integrate with Datadog, New Relic, or Sentry
   - Automatic error tracking and performance profiling
   - Real-time anomaly detection

5. **Custom Business Dashboards**
   - Invoice creation rate over time
   - Payment success/failure metrics
   - Cache hit rate visualization
   - Late fee calculation distribution

These enhancements are **documented but intentionally deferred** for the 48-hour challenge.

---

## Implementation Checklist

### Phase 1: Dependencies
- [ ] Add `structlog>=24.1.0` to `pyproject.toml`
- [ ] Add `prometheus-fastapi-instrumentator>=7.0.0` to `pyproject.toml`
- [ ] Run `uv sync` to update lockfile

### Phase 2: Logging Infrastructure
- [ ] Create `infrastructure/observability/` package
- [ ] Implement `request_id.py` with middleware and contextvars
- [ ] Implement `logging.py` with structlog configuration
- [ ] Add `configure_logging()` call to application startup

### Phase 3: Health Checks
- [ ] Create `entrypoints/http/schemas/health.py` with DTOs
- [ ] Create `entrypoints/http/routes/health.py` with endpoints
- [ ] Register health router in application
- [ ] Add health check to `docker-compose.yml`

### Phase 4: Metrics
- [ ] Implement `infrastructure/observability/metrics.py`
- [ ] Call `setup_metrics()` in application factory
- [ ] Verify `/metrics` endpoint returns Prometheus format

### Phase 5: Integration
- [ ] Add `RequestIdMiddleware` to FastAPI app
- [ ] Update existing use cases to use structured logging
- [ ] Test request_id propagation through log entries

### Phase 6: Testing
- [ ] Unit tests for request_id middleware
- [ ] Unit tests for health check endpoints
- [ ] Integration test for `/metrics` endpoint format
- [ ] Test log output format (JSON vs console)

### Phase 7: Documentation
- [ ] Update README with observability section
- [ ] Document environment variables
- [ ] Add curl examples for health endpoints

---

## Testing Strategy

### Unit Tests

```python
# tests/unit/infrastructure/observability/test_request_id.py
import pytest
from starlette.testclient import TestClient

from mattilda_challenge.infrastructure.observability.request_id import (
    get_request_id,
    RequestIdMiddleware,
)


def test_request_id_generated_when_not_provided(app):
    """Test that request ID is generated if not in headers."""
    client = TestClient(app)
    response = client.get("/health/live")
    
    assert "X-Request-ID" in response.headers
    assert len(response.headers["X-Request-ID"]) == 36  # UUID format


def test_request_id_preserved_when_provided(app):
    """Test that client-provided request ID is preserved."""
    client = TestClient(app)
    response = client.get(
        "/health/live",
        headers={"X-Request-ID": "custom-id-123"},
    )
    
    assert response.headers["X-Request-ID"] == "custom-id-123"
```

```python
# tests/unit/entrypoints/http/routes/test_health.py
import pytest
from unittest.mock import AsyncMock, patch

from fastapi.testclient import TestClient


def test_liveness_returns_alive(app):
    """Test liveness endpoint returns 200."""
    client = TestClient(app)
    response = client.get("/health/live")
    
    assert response.status_code == 200
    assert response.json() == {"status": "alive"}


def test_health_returns_healthy_when_all_deps_up(app, mock_healthy_deps):
    """Test health endpoint when all dependencies are healthy."""
    client = TestClient(app)
    response = client.get("/health")
    
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    assert "database" in data["dependencies"]
    assert "redis" in data["dependencies"]


def test_health_returns_503_when_db_down(app, mock_db_down):
    """Test health endpoint returns 503 when database is down."""
    client = TestClient(app)
    response = client.get("/health")
    
    assert response.status_code == 503
    data = response.json()
    assert data["status"] == "unhealthy"
    assert data["dependencies"]["database"]["status"] == "unhealthy"
```

### Integration Tests

```python
# tests/integration/test_metrics.py
import pytest
from fastapi.testclient import TestClient


def test_metrics_endpoint_returns_prometheus_format(app):
    """Test /metrics returns valid Prometheus format."""
    client = TestClient(app)
    response = client.get("/metrics")
    
    assert response.status_code == 200
    assert "text/plain" in response.headers["content-type"]
    
    # Check for expected metrics
    body = response.text
    assert "http_request_duration_seconds" in body
    assert "http_requests_total" in body
```

---

## Example Log Output

### Development Mode (DEBUG=true)

```
2024-01-20 15:00:00 [info     ] application_starting           environment=development version=1.0.0
2024-01-20 15:00:01 [info     ] creating_invoice               amount=150.00 request_id=abc-123 student_id=550e8400-...
2024-01-20 15:00:01 [info     ] invoice_created                invoice_id=660e8400-... request_id=abc-123 student_id=550e8400-...
2024-01-20 15:00:02 [warning  ] redis_health_check_failed      error=Connection refused request_id=def-456
```

### Production Mode (DEBUG=false)

```json
{"timestamp":"2024-01-20T15:00:00.000000Z","level":"info","message":"application_starting","version":"1.0.0","environment":"production","module":"app","lineno":25}
{"timestamp":"2024-01-20T15:00:01.123456Z","level":"info","message":"creating_invoice","request_id":"abc-123","student_id":"550e8400-...","amount":"150.00","module":"use_cases.create_invoice","lineno":42}
{"timestamp":"2024-01-20T15:00:01.234567Z","level":"info","message":"invoice_created","request_id":"abc-123","invoice_id":"660e8400-...","student_id":"550e8400-...","module":"use_cases.create_invoice","lineno":58}
```

---

## References

- [structlog Documentation](https://www.structlog.org/en/stable/)
- [prometheus-fastapi-instrumentator](https://github.com/trallnag/prometheus-fastapi-instrumentator)
- [12-Factor App: Logs](https://12factor.net/logs)
- [Kubernetes Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
- [OpenTelemetry Python](https://opentelemetry.io/docs/instrumentation/python/) (for future reference)
