# ADR-004: PostgreSQL Persistence with SQLAlchemy and Alembic

## Status

Implemented

## Context

The mattilda_challenge system requires persistent storage for schools, students, invoices, and payments. The persistence layer must:

- **Preserve financial correctness**: Store monetary values with exact decimal precision
- **Respect domain immutability**: Translate between immutable domain entities and mutable ORM models
- **Support UUID identifiers**: Native PostgreSQL UUID type with proper indexing
- **Enable transactional consistency**: ACID guarantees for multi-step operations (e.g., recording payment + updating invoice status)
- **Maintain Clean Architecture**: Infrastructure depends on domain, never the reverse
- **Support asynchronous operations**: FastAPI requires async database access
- **Prevent race conditions**: Row-level locking for concurrent payment processing

This ADR establishes the persistence strategy, ORM patterns, transaction management, migration approach, and data mapping rules that ensure the domain model (ADR-002) is correctly represented in PostgreSQL.

### Key Challenges

1. **Immutable domain vs mutable ORM**: Domain entities are `frozen=True` dataclasses, but SQLAlchemy models must be mutable
2. **UUID value objects**: Domain uses `InvoiceId(value=UUID)`, database uses native `UUID` type
3. **Decimal precision**: Domain uses `Decimal`, database must use `NUMERIC(12, 2)`
4. **Timezone handling**: All timestamps must be UTC-aware in domain, stored as `TIMESTAMP WITH TIME ZONE` in database
5. **Multi-step transactions**: Recording payment requires atomic: (1) save payment, (2) calculate new status, (3) update invoice
6. **Concurrent modifications**: Multiple payments to same invoice must not cause lost updates
7. **Migration management**: Schema evolution must be trackable, reversible, and testable

### Related ADRs

- **[ADR-001](ADR-001-project-initialization.md)**: Project initialization (Clean Architecture, ABC ports, immutability)
- **[ADR-002](ADR-002-domain-model.md)**: Domain model (entities, UUID identifiers, Decimal arithmetic, UTC timestamps)
- **[ADR-003](ADR-003-time-provider.md)**: Time provider (UTC-only policy, time injection)

---

## Decision

### 1. Technology Stack

| Component | Choice | Version |
|-----------|--------|---------|
| Database | PostgreSQL | 16+ |
| ORM | SQLAlchemy | 2.0+ (async) |
| Migration Tool | Alembic | Latest |
| Database Driver | asyncpg | Latest |
| Connection Pooling | SQLAlchemy (via asyncpg) | Default settings |

**Rationale**:
- **PostgreSQL 16+**: Native UUID type, excellent `NUMERIC` support, ACID compliance, `SELECT ... FOR UPDATE` for row locking
- **SQLAlchemy 2.0**: Mature async ORM with explicit query API, excellent type support
- **asyncpg**: Fastest async PostgreSQL driver, required for FastAPI async endpoints
- **Alembic**: Official SQLAlchemy migration tool, supports auto-generation and rollback

---

### 2. Architecture: Data Mapper Pattern

We use the **Data Mapper pattern** to completely separate domain entities from ORM models.

```mermaid
graph TD
    subgraph "Domain Layer"
        DE[Invoice Entity<br/>frozen=True<br/>Pure Python]
        DVO[Value Objects<br/>InvoiceId, Decimal]
    end
    
    subgraph "Infrastructure Layer"
        ORM[InvoiceModel<br/>SQLAlchemy<br/>Mutable]
        Mapper[InvoiceMapper<br/>to_entity / to_model]
        Repo[PostgresInvoiceRepository<br/>Implements port]
    end
    
    DE -.-> Mapper
    Mapper --> ORM
    Repo --> Mapper
    Repo --> ORM
    
    style DE fill:#90EE90
    style ORM fill:#FFB6C1
    style Mapper fill:#87CEEB
```

**Benefits**:
- Domain entities remain pure Python with zero SQLAlchemy dependencies
- ORM models can be mutable (SQLAlchemy requirement)
- Clear separation enables unit testing domain without database
- Changes to database schema don't affect domain layer
- Can swap ORM/database without changing domain

**Trade-off**: Requires mapper functions to translate between layers (adds boilerplate but ensures isolation).

---

### 3. ORM Models (SQLAlchemy 2.0 Style)

All ORM models use SQLAlchemy 2.0 declarative syntax with `Mapped` type hints.

#### 3.1 Base Configuration

```python
from __future__ import annotations

from datetime import datetime
from decimal import Decimal
from typing import Optional
from uuid import UUID

from sqlalchemy import TIMESTAMP, NUMERIC, String, ForeignKey, MetaData
from sqlalchemy.dialects.postgresql import UUID as PG_UUID
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship


# Naming convention for predictable constraint names
convention = {
    "ix": "ix_%(column_0_label)s",
    "uq": "uq_%(table_name)s_%(column_0_name)s",
    "ck": "ck_%(table_name)s_%(constraint_name)s",
    "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
    "pk": "pk_%(table_name)s",
}

metadata = MetaData(naming_convention=convention)


class Base(DeclarativeBase):
    """Base class for all ORM models."""
    
    metadata = metadata
    
    # Type annotation map for Mapped types
    type_annotation_map = {
        datetime: TIMESTAMP(timezone=True),  # Forces TIMESTAMP WITH TIME ZONE
        Decimal: NUMERIC(12, 2),  # Default precision for monetary values
    }
```

**Key decisions**:
- **`DeclarativeBase`**: SQLAlchemy 2.0 base class (replaces old `declarative_base()`)
- **`type_annotation_map`**: Automatic type mapping for `Mapped` annotations
- **`TIMESTAMP(timezone=True)`**: Ensures UTC storage (enforces ADR-003 UTC policy)
- **`NUMERIC(12, 2)`**: Default for monetary values (ADR-002 Decimal requirement)
- **Naming convention**: Predictable constraint names for migrations

#### 3.2 School Model

```python
from sqlalchemy import Index


class SchoolModel(Base):
    """
    ORM model for schools table.
    
    Mutable (SQLAlchemy requirement). Domain entity is immutable.
    """
    __tablename__ = "schools"
    
    # Primary key: UUID
    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),  # Native PostgreSQL UUID
        primary_key=True,
    )
    
    # School attributes
    name: Mapped[str] = mapped_column(String(200), nullable=False)
    address: Mapped[str] = mapped_column(String(500), nullable=False)
    
    # Timestamps (automatically uses TIMESTAMP WITH TIME ZONE)
    created_at: Mapped[datetime] = mapped_column(nullable=False)
    
    # Relationships (lazy loading)
    students: Mapped[list["StudentModel"]] = relationship(
        back_populates="school",
        lazy="select",
        cascade="all, delete-orphan",
    )
    
    # Indexes
    __table_args__ = (
        Index("ix_schools_name", "name"),
    )
```

#### 3.3 Student Model

```python
class StudentModel(Base):
    """ORM model for students table."""
    __tablename__ = "students"
    
    id: Mapped[UUID] = mapped_column(PG_UUID(as_uuid=True), primary_key=True)
    
    # Foreign key to school (immutable - student cannot transfer schools)
    school_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),
        ForeignKey("schools.id", ondelete="RESTRICT"),
        nullable=False,
        index=True,
    )
    
    # Student attributes
    first_name: Mapped[str] = mapped_column(String(100), nullable=False)
    last_name: Mapped[str] = mapped_column(String(100), nullable=False)
    email: Mapped[str] = mapped_column(String(200), nullable=False, unique=True)
    
    # Status: stored as string enum
    status: Mapped[str] = mapped_column(String(20), nullable=False, default="active")
    
    # Timestamps
    enrollment_date: Mapped[datetime] = mapped_column(nullable=False)
    created_at: Mapped[datetime] = mapped_column(nullable=False)
    updated_at: Mapped[datetime] = mapped_column(nullable=False)
    
    # Relationships
    school: Mapped["SchoolModel"] = relationship(back_populates="students")
    invoices: Mapped[list["InvoiceModel"]] = relationship(
        back_populates="student",
        lazy="select",
        cascade="all, delete-orphan",
    )
    
    __table_args__ = (
        Index("ix_students_school_id", "school_id"),
        Index("ix_students_email", "email"),
        Index("ix_students_status", "status"),
    )
```

#### 3.4 Invoice Model

```python
class InvoiceModel(Base):
    """ORM model for invoices table."""
    __tablename__ = "invoices"
    
    id: Mapped[UUID] = mapped_column(PG_UUID(as_uuid=True), primary_key=True)
    
    student_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),
        ForeignKey("students.id", ondelete="RESTRICT"),
        nullable=False,
        index=True,
    )
    
    # Human-readable invoice number (not unique - decorative only)
    invoice_number: Mapped[str] = mapped_column(String(50), nullable=False)
    
    # Monetary amount (NUMERIC(12, 2) via type_annotation_map)
    amount: Mapped[Decimal] = mapped_column(nullable=False)
    
    # Due date
    due_date: Mapped[datetime] = mapped_column(nullable=False, index=True)
    
    # Description
    description: Mapped[str] = mapped_column(String(500), nullable=False)
    
    # Late fee policy: store monthly rate
    late_fee_policy_monthly_rate: Mapped[Decimal] = mapped_column(
        NUMERIC(5, 4),  # 0.0000 to 9.9999 (supports up to 999.99%)
        nullable=False,
    )
    
    # Status: stored as string enum
    status: Mapped[str] = mapped_column(
        String(20), 
        nullable=False, 
        default="pending",
        index=True,
    )
    
    # Timestamps
    created_at: Mapped[datetime] = mapped_column(nullable=False)
    updated_at: Mapped[datetime] = mapped_column(nullable=False)
    
    # Relationships
    student: Mapped["StudentModel"] = relationship(back_populates="invoices")
    payments: Mapped[list["PaymentModel"]] = relationship(
        back_populates="invoice",
        lazy="select",
        cascade="all, delete-orphan",
    )
    
    __table_args__ = (
        Index("ix_invoices_student_id", "student_id"),
        Index("ix_invoices_due_date", "due_date"),
        Index("ix_invoices_status", "status"),
        Index("ix_invoices_student_status", "student_id", "status"),  # Composite
    )
```

#### 3.5 Payment Model

```python
class PaymentModel(Base):
    """ORM model for payments table."""
    __tablename__ = "payments"
    
    id: Mapped[UUID] = mapped_column(PG_UUID(as_uuid=True), primary_key=True)
    
    invoice_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),
        ForeignKey("invoices.id", ondelete="RESTRICT"),
        nullable=False,
        index=True,
    )
    
    # Payment amount (NUMERIC(12, 2))
    amount: Mapped[Decimal] = mapped_column(nullable=False)
    
    # Payment date: when payment was made (may differ from created_at)
    payment_date: Mapped[datetime] = mapped_column(nullable=False, index=True)
    
    # Payment method
    payment_method: Mapped[str] = mapped_column(String(50), nullable=False)
    
    # Optional reference number
    reference_number: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
    
    # Created timestamp: when payment was recorded
    created_at: Mapped[datetime] = mapped_column(nullable=False)
    
    # Relationships
    invoice: Mapped["InvoiceModel"] = relationship(back_populates="payments")
    
    __table_args__ = (
        Index("ix_payments_invoice_id", "invoice_id"),
        Index("ix_payments_payment_date", "payment_date"),
        Index("ix_payments_reference_number", "reference_number"),
    )
```

---

### 4. Data Mapper Functions

Mappers convert between domain entities (immutable) and ORM models (mutable).

#### 4.1 Mapper Pattern

```python
# infrastructure/postgres/mappers/invoice_mapper.py
from __future__ import annotations

from decimal import Decimal
from uuid import UUID

from mattilda_challenge.domain.entities import Invoice
from mattilda_challenge.domain.value_objects import (
    InvoiceId, StudentId, InvoiceStatus, LateFeePolicy
)
from mattilda_challenge.infrastructure.postgres.models import InvoiceModel


class InvoiceMapper:
    """
    Maps between Invoice entity and InvoiceModel ORM.
    
    Responsibilities:
    - Convert UUID value objects to/from raw UUID
    - Convert Decimal amounts (already correct type)
    - Convert InvoiceStatus enum to/from string
    - Reconstruct LateFeePolicy from stored monthly_rate
    
    UTC timestamps: Validation happens in domain entities via validate_utc_timestamp().
    Database stores as TIMESTAMP WITH TIME ZONE. Mappers trust both layers.
    """
    
    @staticmethod
    def to_entity(model: InvoiceModel) -> Invoice:
        """
        Convert ORM model to domain entity.
        
        Args:
            model: SQLAlchemy InvoiceModel
            
        Returns:
            Immutable Invoice entity
        """
        return Invoice(
            id=InvoiceId(value=model.id),
            student_id=StudentId(value=model.student_id),
            invoice_number=model.invoice_number,
            amount=model.amount,  # Already Decimal
            due_date=model.due_date,  # Already datetime with UTC
            description=model.description,
            late_fee_policy=LateFeePolicy(
                monthly_rate=model.late_fee_policy_monthly_rate
            ),
            status=InvoiceStatus(model.status),  # String → Enum
            created_at=model.created_at,
            updated_at=model.updated_at,
        )
    
    @staticmethod
    def to_model(entity: Invoice) -> InvoiceModel:
        """
        Convert domain entity to ORM model.
        
        Args:
            entity: Immutable Invoice entity
            
        Returns:
            Mutable InvoiceModel
        """
        return InvoiceModel(
            id=entity.id.value,  # Value object → UUID
            student_id=entity.student_id.value,
            invoice_number=entity.invoice_number,
            amount=entity.amount,  # Decimal passes through
            due_date=entity.due_date,
            description=entity.description,
            late_fee_policy_monthly_rate=entity.late_fee_policy.monthly_rate,
            status=entity.status.value,  # Enum → String
            created_at=entity.created_at,
            updated_at=entity.updated_at,
        )
```

**Key principles**:
- **Stateless mapper**: No instance state, only pure functions
- **Explicit conversions**: Every type transformation is visible
- **Value object unwrapping**: `entity.id.value` extracts UUID from `InvoiceId`
- **Enum to string**: `entity.status.value` gets string representation
- **Policy decomposition**: Store only `monthly_rate`, reconstruct full `LateFeePolicy`


#### 4.2 UTC Timestamp Strategy

Mappers **assume** that timestamps are already UTC-validated:

1. **Domain entities** validate UTC in `__post_init__` via `validate_utc_timestamp()`
2. **ORM models** store timestamps in `TIMESTAMP WITH TIME ZONE` columns
3. **Mappers trust both layers** - no redundant validation needed

```python
@staticmethod
def to_entity(model: InvoiceModel) -> Invoice:
    """
    Convert ORM model to domain entity.
    
    UTC validation happens in Invoice.__post_init__() - not validated here.
    Database guarantees TIMESTAMP WITH TIME ZONE storage.
    """
    return Invoice(
        id=InvoiceId(value=model.id),
        # ...
        due_date=model.due_date,  # Assumed UTC (validated by domain)
    )
```

**Why no defensive checks in mappers:**
- Domain entities already enforce UTC via `validate_utc_timestamp()` guard
- Database stores in `TIMESTAMP WITH TIME ZONE` (PostgreSQL guarantees)
- Redundant validation adds overhead without benefit
- **Defense-in-depth is at construction, not at every boundary crossing**

If a non-UTC timestamp reaches the mapper, it means:
- Domain validation was bypassed (bug in entity creation), OR
- Database timezone configuration is wrong (infrastructure issue)

Both are caught earlier by entity validation or database constraints.


---

### 5. Unit of Work Pattern (Essential)

The Unit of Work pattern is **essential** (not optional) for mattilda_challenge because:

1. Recording payment requires atomic: (1) save payment, (2) update invoice status
2. Financial correctness demands that partial operations cannot succeed
3. Row-level locking prevents concurrent payment race conditions
4. Explicit transaction boundaries improve debuggability

#### 5.1 Why Unit of Work is Essential

**Recording a payment requires 3 coordinated operations:**

```python
# Without UoW: 3 separate transactions → can partially succeed (BAD)
async def record_payment_bad(invoice_id, amount):
    payment = Payment.create(...)
    await payment_repo.save(payment)  # Transaction 1
    
    invoice = await invoice_repo.get_by_id(invoice_id)  # Transaction 2
    total_paid = await calculate_total(invoice_id)
    
    updated_invoice = invoice.update_status(new_status)
    await invoice_repo.save(updated_invoice)  # Transaction 3
    
    # If transaction 3 fails, payment exists but invoice status is wrong!

# With UoW: Single transaction → atomic commit/rollback (GOOD)
async def record_payment_good(invoice_id, amount):
    async with UnitOfWork(session) as uow:
        payment = Payment.create(...)
        await uow.payments.save(payment)
        
        invoice = await uow.invoices.get_by_id(invoice_id, for_update=True)
        total_paid = await uow.payments.get_total_by_invoice(invoice_id)
        
        updated_invoice = invoice.update_status(new_status)
        await uow.invoices.save(updated_invoice)
        
        await uow.commit()  # All succeed or all rollback atomically
```

#### 5.2 Unit of Work Implementation

```python
# infrastructure/postgres/unit_of_work.py
from __future__ import annotations

from sqlalchemy.ext.asyncio import AsyncSession

from mattilda_challenge.application.ports import (
    SchoolRepository,
    StudentRepository,
    InvoiceRepository,
    PaymentRepository,
)
from mattilda_challenge.infrastructure.adapters import (
    PostgresSchoolRepository,
    PostgresStudentRepository,
    PostgresInvoiceRepository,
    PostgresPaymentRepository,
)


class UnitOfWork:
    """
    Unit of Work pattern for transactional operations.
    
    Ensures all repositories in a use case share the same session
    and transaction. Provides atomic commit/rollback.
    
    Usage:
        async with UnitOfWork(session) as uow:
            # All operations share same transaction
            payment = await uow.payments.save(payment)
            invoice = await uow.invoices.get_by_id(invoice_id, for_update=True)
            updated = invoice.record_payment(payment.amount, now)
            await uow.invoices.save(updated)
            
            # Atomic commit
            await uow.commit()
    """
    
    def __init__(self, session: AsyncSession):
        self._session = session
        
        # All repositories share the same session (same transaction)
        self.schools: SchoolRepository = PostgresSchoolRepository(session)
        self.students: StudentRepository = PostgresStudentRepository(session)
        self.invoices: InvoiceRepository = PostgresInvoiceRepository(session)
        self.payments: PaymentRepository = PostgresPaymentRepository(session)
    
    async def __aenter__(self) -> UnitOfWork:
        """Enter transaction context."""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """
        Exit transaction context with rollback on error.
        
        Note: Session lifecycle is managed by FastAPI's get_session() dependency.
        UoW only owns transaction scope (commit/rollback), not session lifetime.
        """
        if exc_type is not None:
            await self.rollback()
        # Session closing is handled by get_session() - do NOT close here
    
    async def commit(self) -> None:
        """Commit all changes atomically."""
        await self._session.commit()
    
    async def rollback(self) -> None:
        """Rollback all changes."""
        await self._session.rollback()
```

#### 5.3 Transaction Boundary Invariant (Critical)

**Rule**: Repositories must **never** call `commit()` or `rollback()` directly.

All transaction boundaries are owned exclusively by the Unit of Work.

```python
# ❌ WRONG: Repository commits
class PostgresInvoiceRepository(InvoiceRepository):
    async def save(self, invoice: Invoice) -> Invoice:
        model = InvoiceMapper.to_model(invoice)
        self._session.add(model)
        await self._session.commit()  # ❌ NO! Breaks atomicity
        return invoice

# ✅ CORRECT: Repository only flushes
class PostgresInvoiceRepository(InvoiceRepository):
    async def save(self, invoice: Invoice) -> Invoice:
        model = InvoiceMapper.to_model(invoice)
        self._session.add(model)
        await self._session.flush()  # ✅ Write to DB, keep transaction open
        return InvoiceMapper.to_entity(model)
```

**Why this matters:**

If a repository commits, multi-step use cases break atomicity:

```python
# Scenario: Recording a payment
async with UnitOfWork(session) as uow:
    await uow.payments.save(payment)      # If this commits...
    await uow.invoices.save(invoice)      # ...and this fails...
    await uow.commit()                    # ...payment exists but invoice unchanged!
```

**Enforcement:**
- Code review must verify no `commit()` calls in repository methods
- Only `flush()` is allowed (writes to DB without committing transaction)
- Unit tests should use in-memory repositories (no real session)
- Integration tests verify transaction rollback on exceptions



#### 5.4 Row-Level Locking with SELECT ... FOR UPDATE

Repositories support `for_update` parameter for pessimistic locking:

```python
# infrastructure/adapters/invoice_repository.py
class PostgresInvoiceRepository(InvoiceRepository):
    """PostgreSQL implementation of InvoiceRepository port."""
    
    async def get_by_id(
        self, 
        invoice_id: InvoiceId,
        for_update: bool = False,  # Enable row-level lock
    ) -> Optional[Invoice]:
        """
        Get invoice by ID with optional row-level lock.
        
        Args:
            invoice_id: Invoice identifier
            for_update: If True, acquire row lock (prevents concurrent modifications)
            
        Returns:
            Invoice entity or None
        """
        stmt = select(InvoiceModel).where(InvoiceModel.id == invoice_id.value)
        
        if for_update:
            stmt = stmt.with_for_update()  # SELECT ... FOR UPDATE
        
        result = await self._session.execute(stmt)
        model = result.scalar_one_or_none()
        
        if model is None:
            return None
        
        return InvoiceMapper.to_entity(model)
```

**Why `SELECT ... FOR UPDATE` is critical:**

```python
# Scenario: Two concurrent payments for same invoice

# WITHOUT locking (race condition):
# Thread 1: Read invoice (status=pending, amount=1500)
# Thread 2: Read invoice (status=pending, amount=1500)  # Same state!
# Thread 1: Create payment $500, set status=partially_paid
# Thread 2: Create payment $1000, set status=partially_paid  # Wrong!
# Result: Invoice should be "paid" but shows "partially_paid"

# WITH locking (correct):
# Thread 1: Read invoice with lock (status=pending)
# Thread 2: Blocked waiting for lock...
# Thread 1: Create payment $500, set status=partially_paid, commit
# Thread 2: Read invoice (status=partially_paid, sees $500 payment)
# Thread 2: Create payment $1000, set status=paid, commit
# Result: Correct final state
```

---

### 6. Repository Implementation with UoW

Repositories are injected via UnitOfWork in use cases:

```python
# application/use_cases/record_payment.py
from __future__ import annotations

from decimal import Decimal
from datetime import datetime

from mattilda_challenge.domain.entities import Payment, Invoice
from mattilda_challenge.domain.value_objects import InvoiceId, InvoiceStatus
from mattilda_challenge.domain.exceptions import (
    InvoiceNotFoundError,
    InvalidPaymentAmountError,
)
from mattilda_challenge.infrastructure.postgres.unit_of_work import UnitOfWork


class RecordPaymentUseCase:
    """
    Use case: Record payment against an invoice.
    
    Ensures atomic operation:
    1. Create payment record
    2. Calculate new invoice status
    3. Update invoice status
    
    All three succeed or all three rollback.
    """
    
    async def execute(
        self,
        uow: UnitOfWork,
        invoice_id: InvoiceId,
        amount: Decimal,
        payment_date: datetime,
        payment_method: str,
        now: datetime,
    ) -> tuple[Payment, Invoice]:
        """
        Record payment and update invoice status atomically.
        
        Args:
            uow: Unit of Work (transaction scope)
            invoice_id: Target invoice
            amount: Payment amount
            payment_date: When payment was made
            payment_method: How payment was made
            now: Current timestamp
            
        Returns:
            Tuple of (created payment, updated invoice)
            
        Raises:
            InvoiceNotFoundError: Invoice doesn't exist
            InvalidPaymentAmountError: Amount exceeds balance due
        """
        # Load invoice with row-level lock (prevents concurrent modifications)
        invoice = await uow.invoices.get_by_id(invoice_id, for_update=True)
        
        if invoice is None:
            raise InvoiceNotFoundError(f"Invoice {invoice_id} not found")
        
        # Validate payment amount against remaining balance
        total_paid = await uow.payments.get_total_by_invoice(invoice_id)
        balance_due = invoice.amount - total_paid
        
        if amount > balance_due:
            raise InvalidPaymentAmountError(
                f"Payment {amount} exceeds balance due {balance_due}"
            )
        
        # Create payment
        payment = Payment.create(
            invoice_id=invoice_id,
            amount=amount,
            payment_date=payment_date,
            payment_method=payment_method,
            reference_number=None,
            now=now,
        )
        
        await uow.payments.save(payment)
        
        # Calculate new status
        new_total_paid = total_paid + amount
        
        if new_total_paid >= invoice.amount:
            new_status = InvoiceStatus.PAID
        else:
            new_status = InvoiceStatus.PARTIALLY_PAID
        
        # Update invoice
        updated_invoice = invoice.update_status(new_status, now)
        await uow.invoices.save(updated_invoice)
        
        # Atomic commit (all succeed or all rollback)
        await uow.commit()
        
        return payment, updated_invoice
```

---

### 7. Database Session Management

#### 7.1 Async Engine and Session Factory

```python
# infrastructure/postgres/database.py
from __future__ import annotations

from typing import AsyncGenerator

from sqlalchemy.ext.asyncio import (
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)

from mattilda_challenge.config import settings


# Create async engine
engine = create_async_engine(
    settings.database_url,  # postgresql+asyncpg://user:pass@host/db
    echo=settings.debug,  # Log SQL in debug mode
    pool_size=10,
    max_overflow=20,
    pool_pre_ping=True,  # Verify connections before use
)

# Session factory
AsyncSessionLocal = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
)


async def get_session() -> AsyncGenerator[AsyncSession, None]:
    """
    Dependency injection for async session.
    
    Usage in FastAPI:
        @app.post("/payments")
        async def record_payment(
            request: PaymentRequest,
            session: AsyncSession = Depends(get_session)
        ):
            async with UnitOfWork(session) as uow:
                ...
    
    Yields:
        AsyncSession instance
    """
    async with AsyncSessionLocal() as session:
        try:
            yield session
            # Note: Commit is handled by UnitOfWork
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()
```

#### 7.2 Usage in FastAPI

```python
# entrypoints/http/routes/payments.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession

from mattilda_challenge.infrastructure.postgres.database import get_session
from mattilda_challenge.infrastructure.postgres.unit_of_work import UnitOfWork
from mattilda_challenge.application.use_cases import RecordPaymentUseCase

router = APIRouter(prefix="/payments", tags=["Payments"])


@router.post("/", status_code=201)
async def record_payment(
    request: RecordPaymentRequest,  # amount: str in schema
    session: AsyncSession = Depends(get_session),
):
    """
    Record a payment against an invoice.
    
    Note: RecordPaymentRequest.amount should be str (not float)
    to preserve decimal precision across the API boundary.
    """
    try:
        async with UnitOfWork(session) as uow:
            use_case = RecordPaymentUseCase()
            
            payment, invoice = await use_case.execute(
                uow=uow,
                invoice_id=InvoiceId.from_string(request.invoice_id),
                amount=Decimal(str(request.amount)),  # Convert via string for safety
                payment_date=request.payment_date,
                payment_method=request.payment_method,
                now=time_provider.now(),
            )
            
            return PaymentResponse.from_entities(payment, invoice)
    
    except InvoiceNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except InvalidPaymentAmountError as e:
        raise HTTPException(status_code=400, detail=str(e))
```

---

### 8. Migration Strategy (Alembic)

#### 8.1 Initial Setup

```bash
# Initialize Alembic
alembic init alembic

# Edit alembic.ini to point to database
# sqlalchemy.url = postgresql+asyncpg://user:pass@localhost/mattilda_db
```


**Important: Alembic runs in synchronous mode** even when your application uses async SQLAlchemy.

```python
# alembic/env.py

# ❌ WRONG: Trying to use async in migrations
from sqlalchemy.ext.asyncio import create_async_engine

async def run_migrations():
    engine = create_async_engine(...)
    await engine.dispose()  # Won't work - Alembic is sync

# ✅ CORRECT: Use sync engine in migrations
from sqlalchemy import create_engine

def run_migrations():
    engine = create_engine(
        "postgresql://user:pass@host/db"  # Note: No +asyncpg
    )
    # ... run migrations
```

**Why:**
- Alembic's migration runner is synchronous
- Migrations execute DDL (schema changes), which doesn't benefit from async
- Runtime application uses async (`asyncpg`), migrations use sync (`psycopg`)

**Practical impact:**
- Alembic config URL: `postgresql://...` (sync)
- Application config URL: `postgresql+asyncpg://...` (async)
- Keep both URLs in configuration (different drivers)



#### 8.2 Migration File Structure

```mermaid
graph TD
    A[alembic/] --> B[versions/]
    A --> C[env.py]
    A --> D[script.py.mako]
    A --> E[alembic.ini]
    
    B --> F[001_initial_schema.py]
    B --> G[002_add_indexes.py]
    B --> H[003_add_constraints.py]
    
    style A fill:#87CEEB
    style B fill:#90EE90
```

#### 8.3 Example Migration: Initial Schema

```python
# alembic/versions/001_initial_schema.py
"""Initial schema

Revision ID: 001
Revises: 
Create Date: 2025-01-16 12:00:00

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import UUID

revision: str = '001'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Create all tables."""
    
    # Schools table
    op.create_table(
        'schools',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('name', sa.String(200), nullable=False),
        sa.Column('address', sa.String(500), nullable=False),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), nullable=False),
    )
    op.create_index('ix_schools_name', 'schools', ['name'])
    
    # Students table
    op.create_table(
        'students',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('school_id', UUID(as_uuid=True), nullable=False),
        sa.Column('first_name', sa.String(100), nullable=False),
        sa.Column('last_name', sa.String(100), nullable=False),
        sa.Column('email', sa.String(200), nullable=False, unique=True),
        sa.Column('status', sa.String(20), nullable=False, server_default='active'),
        sa.Column('enrollment_date', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.Column('updated_at', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(['school_id'], ['schools.id'], ondelete='RESTRICT'),
    )
    op.create_index('ix_students_school_id', 'students', ['school_id'])
    op.create_index('ix_students_email', 'students', ['email'])
    op.create_index('ix_students_status', 'students', ['status'])
    
    # Invoices table
    op.create_table(
        'invoices',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('student_id', UUID(as_uuid=True), nullable=False),
        sa.Column('invoice_number', sa.String(50), nullable=False),
        sa.Column('amount', sa.NUMERIC(12, 2), nullable=False),
        sa.Column('due_date', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.Column('description', sa.String(500), nullable=False),
        sa.Column('late_fee_policy_monthly_rate', sa.NUMERIC(5, 4), nullable=False),
        sa.Column('status', sa.String(20), nullable=False, server_default='pending'),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.Column('updated_at', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(['student_id'], ['students.id'], ondelete='RESTRICT'),
    )
    op.create_index('ix_invoices_student_id', 'invoices', ['student_id'])
    op.create_index('ix_invoices_due_date', 'invoices', ['due_date'])
    op.create_index('ix_invoices_status', 'invoices', ['status'])
    op.create_index('ix_invoices_student_status', 'invoices', ['student_id', 'status'])
    
    # Payments table
    op.create_table(
        'payments',
        sa.Column('id', UUID(as_uuid=True), primary_key=True),
        sa.Column('invoice_id', UUID(as_uuid=True), nullable=False),
        sa.Column('amount', sa.NUMERIC(12, 2), nullable=False),
        sa.Column('payment_date', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.Column('payment_method', sa.String(50), nullable=False),
        sa.Column('reference_number', sa.String(100), nullable=True),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(['invoice_id'], ['invoices.id'], ondelete='RESTRICT'),
    )
    op.create_index('ix_payments_invoice_id', 'payments', ['invoice_id'])
    op.create_index('ix_payments_payment_date', 'payments', ['payment_date'])


def downgrade() -> None:
    """Drop all tables (reverse order)."""
    op.drop_table('payments')
    op.drop_table('invoices')
    op.drop_table('students')
    op.drop_table('schools')
```

#### 8.4 Running Migrations

```bash
# Create new migration
make migrate-create NAME="add_feature"

# Apply migrations
make migrate

# Rollback one step
make migrate-rollback

# Rollback to specific revision
make migrate-rollback-to REVISION=001
```


### 9. Database Index Strategy

Indexes are added based on **query patterns** identified from use cases and API endpoints. Every index has a specific purpose tied to application behavior.

#### 9.1 Index Design Principles

**Rule 1: Index foreign keys**
- PostgreSQL does NOT automatically index foreign keys
- Every foreign key is queried in joins
- Without indexes, foreign key joins cause full table scans

**Rule 2: Index query predicates**
- Any column in `WHERE` clauses should be indexed
- Columns used in `ORDER BY` benefit from indexes
- Frequently filtered fields need indexes

**Rule 3: Composite indexes for multi-column queries**
- Order matters: most selective column first
- Use composite indexes when columns are frequently queried together
- Single-column indexes cannot be efficiently combined by PostgreSQL

**Rule 4: Trade-off awareness**
- Indexes speed up reads but slow down writes
- Each index adds storage overhead (~10-20% per index)
- Don't index low-cardinality columns (e.g., boolean flags with 50/50 distribution)

#### 9.2 Index Justification by Table

##### Schools Table

```python
__table_args__ = (
    Index("ix_schools_name", "name"),
)
```

| Index | Justification | Query Pattern |
|-------|---------------|---------------|
| `ix_schools_name` | Search/filter schools by name | `GET /schools?name=...` (search API) |
| Primary key on `id` | Lookup by UUID | `GET /schools/{id}` |

**Why not index `address`?**
- Address searches are rare (not in core use cases)
- Full-text search would be better if needed (out of scope)

##### Students Table

```python
__table_args__ = (
    Index("ix_students_school_id", "school_id"),
    Index("ix_students_email", "email"),
    Index("ix_students_status", "status"),
)
```

| Index | Justification | Query Pattern |
|-------|---------------|---------------|
| `ix_students_school_id` | **Critical**: List all students in a school | `GET /schools/{id}/students` (very common) |
| `ix_students_email` | Unique constraint enforcement + login lookup | Unique email validation, authentication (future) |
| `ix_students_status` | Filter by enrollment status | `GET /students?status=active` |
| Primary key on `id` | Lookup by UUID | `GET /students/{id}` |

**Why `school_id` is critical**:
```sql
-- Common query: "Get all students in School X"
SELECT * FROM students WHERE school_id = 'abc-123...'

-- Without index: FULL TABLE SCAN (slow as students table grows)
-- With index: INDEX SCAN (fast, O(log n) lookup)
```

**Use case impact**:
- **School account statement**: Must aggregate all students in school
- **Student enrollment list**: Dashboard shows students per school
- **Invoice creation**: Must validate student belongs to school

##### Invoices Table

```python
__table_args__ = (
    Index("ix_invoices_student_id", "student_id"),
    Index("ix_invoices_due_date", "due_date"),
    Index("ix_invoices_status", "status"),
    Index("ix_invoices_student_status", "student_id", "status"),  # Composite
)
```

| Index | Justification | Query Pattern |
|-------|---------------|---------------|
| `ix_invoices_student_id` | **Critical**: List all invoices for a student | `GET /students/{id}/invoices` |
| `ix_invoices_due_date` | **Critical**: Find overdue invoices | Late fee calculation, overdue reports |
| `ix_invoices_status` | Filter by payment status | `GET /invoices?status=pending` |
| `ix_invoices_student_status` | **Composite**: Pending invoices for student | Student account statement (most common query) |
| Primary key on `id` | Lookup by UUID | `GET /invoices/{id}` |

**Composite index deep dive: `(student_id, status)`**

This is the **most important index** in the system. Here's why:

```sql
-- Most common query: "Get pending invoices for Student X"
-- This powers student account statements (very frequent)
SELECT * FROM invoices 
WHERE student_id = 'student-uuid' 
  AND status IN ('pending', 'partially_paid')

-- Without composite index:
-- Option A: Use ix_invoices_student_id → scan all student's invoices, filter status (slower)
-- Option B: Use ix_invoices_status → scan all pending invoices, filter student (much slower)

-- With composite index (student_id, status):
-- Direct lookup: O(log n) for specific (student, status) combination
```

**Why column order matters**:
```sql
-- Composite index (student_id, status) can accelerate:
WHERE student_id = X                          -- ✅ Uses index
WHERE student_id = X AND status = Y           -- ✅ Uses index (full match)
WHERE status = Y                              -- ❌ Cannot use index (needs leftmost column)

-- That's why we have BOTH:
-- ix_invoices_student_status (student_id, status) -- For filtered queries
-- ix_invoices_status (status)                     -- For status-only queries
```

**Performance impact**:
```
# Students table: 10,000 students
# Invoices table: 100,000 invoices (avg 10 per student)

Query: "Get pending invoices for student X"

Without index:
- Full table scan: 100,000 rows
- Filter in application: ~10 rows
- Time: ~500ms

With ix_invoices_student_id:
- Index scan: ~10 rows for student
- Filter status in application: ~3 rows
- Time: ~50ms (10x faster)

With ix_invoices_student_status:
- Direct index lookup: ~3 rows
- No filtering needed
- Time: ~5ms (100x faster)
```

##### Payments Table

```python
__table_args__ = (
    Index("ix_payments_invoice_id", "invoice_id"),
    Index("ix_payments_payment_date", "payment_date"),
    Index("ix_payments_reference_number", "reference_number"),
)
```

| Index | Justification | Query Pattern |
|-------|---------------|---------------|
| `ix_payments_invoice_id` | **Critical**: Calculate total paid per invoice | Balance due calculation, payment history |
| `ix_payments_payment_date` | Date range reports | `GET /payments?start_date=...&end_date=...` |
| `ix_payments_reference_number` | Payment reconciliation lookup | `GET /payments?reference=TXN-123` |
| Primary key on `id` | Lookup by UUID | `GET /payments/{id}` |

**Why `invoice_id` is critical**:
```sql
-- Balance calculation (happens on EVERY payment recording):
SELECT COALESCE(SUM(amount), 0) 
FROM payments 
WHERE invoice_id = 'invoice-uuid'

-- Without index: FULL TABLE SCAN of payments table
-- With index: INDEX SCAN on subset (O(log n) + O(k) where k = payments for invoice)
```

**Use case: Recording a payment**
```python
async def record_payment(invoice_id, amount):
    # Step 1: Calculate current balance (requires ix_payments_invoice_id)
    total_paid = await payments.get_total_by_invoice(invoice_id)
    
    # Step 2: Validate amount doesn't exceed balance
    balance_due = invoice.amount - total_paid
    
    # Step 3: Determine new status
    if total_paid + amount >= invoice.amount:
        new_status = InvoiceStatus.PAID
    
    # Without ix_payments_invoice_id, this query is slow on EVERY payment
```

#### 9.3 Indexes NOT Added (and why)

| Column | Why NOT indexed |
|--------|-----------------|
| `students.first_name` | Low selectivity, rarely queried alone |
| `students.last_name` | Low selectivity, rarely queried alone |
| `invoices.invoice_number` | Decorative field (UUID `id` is real identifier) |
| `invoices.description` | Full-text search would be better (out of scope) |
| `invoices.amount` | Numeric ranges rarely queried (account statements use aggregates) |
| `payments.amount` | Numeric field, no range queries in use cases |
| `payments.payment_method` | Low cardinality (~5-10 values), filtered infrequently |

**Low cardinality example**:
```sql
-- payment_method has ~5 values: cash, card, bank_transfer, check, online
-- Indexing doesn't help much:
SELECT * FROM payments WHERE payment_method = 'cash'

-- PostgreSQL might choose sequential scan anyway if result set is >5-10% of table
-- Index would slow down writes without helping reads
```

#### 9.4 Query Performance Testing

After implementing indexes, verify performance with `EXPLAIN ANALYZE`:

```sql
-- Test: Get pending invoices for student (should use composite index)
EXPLAIN ANALYZE
SELECT * FROM invoices 
WHERE student_id = 'uuid-here' 
  AND status = 'pending';

-- Expected output:
--   Index Scan using ix_invoices_student_status
--   Rows: ~3  (actual rows returned)
--   Time: 0.5ms

-- ❌ BAD output (missing index):
--   Seq Scan on invoices
--   Rows: 100000  (scanned all rows)
--   Time: 500ms
```

**Add to integration tests**:
```python
async def test_invoice_query_uses_index():
    """Verify composite index is used for common query."""
    stmt = select(InvoiceModel).where(
        and_(
            InvoiceModel.student_id == student_id,
            InvoiceModel.status == "pending"
        )
    )
    
    # Execute with EXPLAIN
    explain = await session.execute(text(f"EXPLAIN {stmt}"))
    plan = explain.scalar()
    
    # Verify index is used
    assert "ix_invoices_student_status" in plan
    assert "Seq Scan" not in plan  # No full table scan
```

#### 9.5 Index Maintenance Considerations

**Monitoring**:
```sql
-- Check index usage (PostgreSQL statistics)
SELECT schemaname, tablename, indexname, idx_scan, idx_tup_read
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY idx_scan ASC;

-- Unused indexes have idx_scan = 0
-- Consider dropping if unused after observation period
```

**Reindexing** (future):
```sql
-- If index bloat occurs (after many updates/deletes)
REINDEX INDEX CONCURRENTLY ix_invoices_student_status;
```

**Migration strategy**:
```python
# Create indexes CONCURRENTLY in production (no table lock)
def upgrade():
    op.create_index(
        'ix_invoices_student_status',
        'invoices',
        ['student_id', 'status'],
        postgresql_concurrently=True,  # No downtime
    )
```

#### 9.6 Index Summary Table

| Table | Index | Type | Purpose | Query Frequency |
|-------|-------|------|---------|-----------------|
| schools | id (PK) | B-tree | Lookup | High |
| schools | name | B-tree | Search | Medium |
| students | id (PK) | B-tree | Lookup | High |
| students | school_id | B-tree | **Join/Filter** | **Very High** |
| students | email | B-tree (unique) | Constraint | Medium |
| students | status | B-tree | Filter | Medium |
| invoices | id (PK) | B-tree | Lookup | High |
| invoices | student_id | B-tree | **Join/Filter** | **Very High** |
| invoices | due_date | B-tree | **Range queries** | **High** |
| invoices | status | B-tree | Filter | High |
| invoices | (student_id, status) | B-tree (composite) | **Filtered joins** | **Very High** |
| payments | id (PK) | B-tree | Lookup | High |
| payments | invoice_id | B-tree | **Aggregation** | **Very High** |
| payments | payment_date | B-tree | Range queries | Medium |
| payments | reference_number | B-tree | Lookup | Low |

**Priority**: Bold = Critical for performance

---

## Where to Insert This Section

Insert as **Section 9** after "Database Session Management" (current Section 7) and before "Consequences".

The section should come after implementation details (ORM, mappers, UoW, sessions) but before consequences, as it's a detailed implementation consideration that affects performance characteristics discussed in "Consequences."


---

## Consequences

### Positive

- **Financial correctness**: `NUMERIC` columns ensure exact decimal precision
- **Atomic transactions**: UnitOfWork ensures all-or-nothing semantics for multi-step operations
- **Race condition prevention**: `SELECT ... FOR UPDATE` prevents concurrent modification bugs
- **Type safety**: UUID value objects prevent ID confusion
- **Clean Architecture**: Domain isolated from SQLAlchemy
- **Testability**: Domain can be tested without database
- **Migration tracking**: Alembic provides version control for schema
- **Performance**: Database aggregation for account statements
- **Async support**: Native async/await with asyncpg
- **Referential integrity**: Foreign keys with `RESTRICT` prevent invalid deletes

### Negative

- **Boilerplate**: Mappers add translation layer (required for isolation)
- **Learning curve**: SQLAlchemy 2.0 async API, UnitOfWork pattern
- **Migration discipline**: Requires careful review of auto-generated migrations
- **Connection pooling**: Must configure pool sizes for production load

### Trade-offs

- **Data Mapper vs Active Record**: Data Mapper adds boilerplate but preserves domain purity
- **Explicit queries vs lazy loading**: Explicit queries are more verbose but avoid N+1 problems
- **Unit of Work complexity**: Adds pattern overhead but ensures correctness in financial operations

---

## Alternatives Considered

### 1. Repository-Level Sessions (Without UoW)

Give each repository its own session.

**Rejected**:
- Multi-step operations (save payment + update invoice) become multiple transactions
- Partial success possible (payment saved, invoice update fails)
- Cannot use row-level locking across repositories
- Financial data consistency cannot be guaranteed

### 2. Active Record Pattern

Use SQLAlchemy models directly as domain entities.

**Rejected**:
- Domain entities would depend on SQLAlchemy (violates Clean Architecture)
- Entities would be mutable (violates ADR-001 immutability requirement)
- Testing requires database or complex mocking
- Cannot use `frozen=True` dataclasses

### 3. Optimistic Locking Instead of Pessimistic

Use version columns instead of `SELECT ... FOR UPDATE`.

**Rejected**:
- Requires retry logic in use cases
- More complex to implement correctly
- Pessimistic locking is simpler and sufficient for this use case
- Financial systems typically use pessimistic locking

---

## Implementation Checklist

- [ ] Create `Base` class with `type_annotation_map` and naming conventions
- [ ] Define ORM models: `SchoolModel`, `StudentModel`, `InvoiceModel`, `PaymentModel`
- [ ] Create mapper classes: `SchoolMapper`, `StudentMapper`, `InvoiceMapper`, `PaymentMapper`
- [ ] Implement `UnitOfWork` class with all repositories
- [ ] Implement repository adapters with `for_update` support
- [ ] Set up async engine and session factory
- [ ] Initialize Alembic configuration
- [ ] Create initial migration (`001_initial_schema.py`)
- [ ] Update use cases to use `UnitOfWork`
- [ ] Write repository integration tests
- [ ] Document migration workflow in README
- [ ] Add database health check endpoint

---

## Related ADRs

- **[ADR-001](ADR-001-project-initialization.md)**: Project initialization (Clean Architecture, immutability, ABC ports)
- **[ADR-002](ADR-002-domain-model.md)**: Domain model (entities, UUID identifiers, Decimal arithmetic)
- **[ADR-003](ADR-003-time-provider.md)**: Time provider (UTC-only policy)
- **[ADR-005](ADR-005.md)**: REST API Design
- **[ADR-006](ADR-006.md)**: Redis Caching Strategy
- **[ADR-007](ADR-007.md)**: Offset-Based Pagination
- **[ADR-010](ADR-010.md)**: UseCase Pattern and Error Handling Strategy

---

## References

- [Cosmic Python - Repository Pattern](https://www.cosmicpython.com/book/chapter_02_repository.html)
- [Cosmic Python - Unit of Work](https://www.cosmicpython.com/book/chapter_06_uow.html)
- [SQLAlchemy 2.0 Documentation](https://docs.sqlalchemy.org/en/20/)
- [Alembic Documentation](https://alembic.sqlalchemy.org/)
